{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:CNN extract features of image and RNN makes words based on the features from CNN.** \n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer: I remained the number, the  Resize is based on the input image size, but what I tried to change is random crop. I set a various crop size, but there was not much idfference, and to catch the feature the crop size should be large, so I used 224.** \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:I set the numbers as widely used parameters. The embedding size is based on the imasge input size, and the voca threshold is based on average word count, because most of noun words are larger than 5 words. ** \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer: Adan optimzer is widely used for CNN and RNN, and I don't know better optimizer than Adam.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 383/414113 [00:00<01:48, 3826.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 830/414113 [00:00<01:43, 3998.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1265/414113 [00:00<01:40, 4096.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1700/414113 [00:00<01:38, 4167.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2142/414113 [00:00<01:37, 4238.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2576/414113 [00:00<01:36, 4268.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3015/414113 [00:00<01:35, 4303.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3449/414113 [00:00<01:35, 4312.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3892/414113 [00:00<01:34, 4346.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4322/414113 [00:01<01:34, 4331.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4762/414113 [00:01<01:34, 4349.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5215/414113 [00:01<01:32, 4399.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5651/414113 [00:01<01:35, 4274.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 6089/414113 [00:01<01:34, 4304.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6518/414113 [00:01<01:37, 4181.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6948/414113 [00:01<01:36, 4215.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7388/414113 [00:01<01:35, 4268.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7846/414113 [00:01<01:33, 4355.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8292/414113 [00:01<01:32, 4386.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8733/414113 [00:02<01:32, 4391.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9173/414113 [00:02<01:32, 4361.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9620/414113 [00:02<01:32, 4391.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10060/414113 [00:02<01:31, 4392.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10500/414113 [00:02<01:32, 4380.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10939/414113 [00:02<01:32, 4363.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11384/414113 [00:02<01:31, 4389.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11827/414113 [00:02<01:31, 4399.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12275/414113 [00:02<01:30, 4422.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12718/414113 [00:02<01:31, 4392.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13166/414113 [00:03<01:30, 4418.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13608/414113 [00:03<01:31, 4389.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14053/414113 [00:03<01:30, 4406.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14495/414113 [00:03<01:30, 4408.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14936/414113 [00:03<01:31, 4376.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 15379/414113 [00:03<01:30, 4390.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 15819/414113 [00:04<03:51, 1720.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16256/414113 [00:04<03:09, 2102.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16717/414113 [00:04<02:38, 2512.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17153/414113 [00:04<02:17, 2877.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17601/414113 [00:04<02:03, 3222.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18061/414113 [00:04<01:51, 3540.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18524/414113 [00:04<01:43, 3809.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 18970/414113 [00:04<01:39, 3983.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19414/414113 [00:04<01:36, 4109.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19858/414113 [00:05<01:33, 4201.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20301/414113 [00:05<01:32, 4246.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 20747/414113 [00:05<01:31, 4306.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21210/414113 [00:05<01:29, 4396.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21664/414113 [00:05<01:28, 4437.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22121/414113 [00:05<01:27, 4475.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22583/414113 [00:05<01:26, 4515.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23062/414113 [00:05<01:25, 4593.62it/s]\n",
      "\u001b[A\u001b[A\n",
      "  6%|▌         | 23524/414113 [00:05<01:25, 4585.72it/s]\u001b[A\n",
      "  6%|▌         | 23985/414113 [00:05<01:26, 4525.51it/s]\u001b[A\n",
      "  6%|▌         | 24439/414113 [00:06<01:26, 4483.32it/s]\u001b[A\n",
      "  6%|▌         | 24903/414113 [00:06<01:25, 4526.50it/s]\u001b[A\n",
      "  6%|▌         | 25357/414113 [00:06<01:25, 4522.02it/s]\u001b[A\n",
      "  6%|▌         | 25810/414113 [00:06<01:26, 4498.18it/s]\u001b[A\n",
      "  6%|▋         | 26261/414113 [00:06<01:26, 4477.90it/s]\u001b[A\n",
      "  6%|▋         | 26710/414113 [00:06<01:27, 4444.62it/s]\u001b[A\n",
      "  7%|▋         | 27155/414113 [00:06<01:27, 4399.04it/s]\u001b[A\n",
      "  7%|▋         | 27605/414113 [00:06<01:27, 4428.23it/s]\u001b[A\n",
      "  7%|▋         | 28049/414113 [00:06<01:27, 4400.45it/s]\u001b[A\n",
      "  7%|▋         | 28490/414113 [00:06<01:27, 4401.90it/s]\u001b[A\n",
      "  7%|▋         | 28931/414113 [00:07<01:27, 4386.96it/s]\u001b[A\n",
      "  7%|▋         | 29370/414113 [00:07<01:28, 4364.75it/s]\u001b[A\n",
      "  7%|▋         | 29808/414113 [00:07<01:27, 4367.31it/s]\u001b[A\n",
      "  7%|▋         | 30245/414113 [00:07<01:28, 4348.13it/s]\u001b[A\n",
      "  7%|▋         | 30680/414113 [00:07<01:28, 4327.43it/s]\u001b[A\n",
      "  8%|▊         | 31147/414113 [00:07<01:26, 4422.42it/s]\u001b[A\n",
      "  8%|▊         | 31590/414113 [00:07<01:26, 4399.49it/s]\u001b[A\n",
      "  8%|▊         | 32036/414113 [00:07<01:26, 4416.55it/s]\u001b[A\n",
      "  8%|▊         | 32478/414113 [00:07<01:27, 4371.84it/s]\u001b[A\n",
      "  8%|▊         | 32916/414113 [00:07<01:27, 4360.17it/s]\u001b[A\n",
      "  8%|▊         | 33353/414113 [00:08<01:28, 4304.36it/s]\u001b[A\n",
      "  8%|▊         | 33784/414113 [00:08<01:28, 4303.16it/s]\u001b[A\n",
      "  8%|▊         | 34218/414113 [00:08<01:28, 4313.87it/s]\u001b[A\n",
      "  8%|▊         | 34650/414113 [00:08<01:28, 4296.22it/s]\u001b[A\n",
      "  8%|▊         | 35081/414113 [00:08<01:28, 4298.86it/s]\u001b[A\n",
      "  9%|▊         | 35516/414113 [00:08<01:27, 4312.98it/s]\u001b[A\n",
      "  9%|▊         | 35953/414113 [00:08<01:27, 4329.52it/s]\u001b[A\n",
      "  9%|▉         | 36406/414113 [00:08<01:26, 4385.19it/s]\u001b[A\n",
      "  9%|▉         | 36852/414113 [00:08<01:25, 4405.56it/s]\u001b[A\n",
      "  9%|▉         | 37293/414113 [00:08<01:25, 4397.46it/s]\u001b[A\n",
      "  9%|▉         | 37736/414113 [00:09<01:25, 4406.08it/s]\u001b[A\n",
      "  9%|▉         | 38189/414113 [00:09<01:24, 4440.32it/s]\u001b[A\n",
      "  9%|▉         | 38634/414113 [00:09<01:24, 4421.22it/s]\u001b[A\n",
      "  9%|▉         | 39077/414113 [00:09<01:25, 4395.82it/s]\u001b[A\n",
      " 10%|▉         | 39520/414113 [00:09<01:25, 4405.44it/s]\u001b[A\n",
      " 10%|▉         | 39972/414113 [00:09<01:24, 4438.49it/s]\u001b[A\n",
      " 10%|▉         | 40425/414113 [00:09<01:23, 4463.49it/s]\u001b[A\n",
      " 10%|▉         | 40877/414113 [00:09<01:23, 4478.39it/s]\u001b[A\n",
      " 10%|▉         | 41325/414113 [00:09<01:23, 4470.89it/s]\u001b[A\n",
      " 10%|█         | 41773/414113 [00:10<01:24, 4419.56it/s]\u001b[A\n",
      " 10%|█         | 42216/414113 [00:10<01:24, 4382.89it/s]\u001b[A\n",
      " 10%|█         | 42670/414113 [00:10<01:23, 4426.82it/s]\u001b[A\n",
      " 10%|█         | 43113/414113 [00:10<01:24, 4393.50it/s]\u001b[A\n",
      " 11%|█         | 43564/414113 [00:10<01:23, 4426.14it/s]\u001b[A\n",
      " 11%|█         | 44007/414113 [00:10<01:24, 4403.26it/s]\u001b[A\n",
      " 11%|█         | 44467/414113 [00:10<01:22, 4459.74it/s]\u001b[A\n",
      " 11%|█         | 44916/414113 [00:10<01:22, 4467.20it/s]\u001b[A\n",
      " 11%|█         | 45366/414113 [00:10<01:22, 4476.39it/s]\u001b[A\n",
      " 11%|█         | 45814/414113 [00:10<01:23, 4428.31it/s]\u001b[A\n",
      " 11%|█         | 46269/414113 [00:11<01:22, 4463.76it/s]\u001b[A\n",
      " 11%|█▏        | 46716/414113 [00:11<01:22, 4431.62it/s]\u001b[A\n",
      " 11%|█▏        | 47160/414113 [00:11<01:22, 4427.82it/s]\u001b[A\n",
      " 11%|█▏        | 47607/414113 [00:11<01:22, 4439.14it/s]\u001b[A\n",
      " 12%|█▏        | 48066/414113 [00:11<01:21, 4481.01it/s]\u001b[A\n",
      " 12%|█▏        | 48521/414113 [00:11<01:21, 4500.14it/s]\u001b[A\n",
      " 12%|█▏        | 48972/414113 [00:11<01:21, 4493.53it/s]\u001b[A\n",
      " 12%|█▏        | 49422/414113 [00:11<01:21, 4494.91it/s]\u001b[A\n",
      " 12%|█▏        | 49873/414113 [00:11<01:20, 4499.41it/s]\u001b[A\n",
      " 12%|█▏        | 50323/414113 [00:11<01:21, 4478.45it/s]\u001b[A\n",
      " 12%|█▏        | 50773/414113 [00:12<01:21, 4482.18it/s]\u001b[A\n",
      " 12%|█▏        | 51222/414113 [00:12<01:21, 4439.47it/s]\u001b[A\n",
      " 12%|█▏        | 51671/414113 [00:12<01:21, 4453.85it/s]\u001b[A\n",
      " 13%|█▎        | 52117/414113 [00:12<01:21, 4455.27it/s]\u001b[A\n",
      " 13%|█▎        | 52563/414113 [00:12<01:21, 4442.18it/s]\u001b[A\n",
      " 13%|█▎        | 53012/414113 [00:12<01:21, 4454.91it/s]\u001b[A\n",
      " 13%|█▎        | 53462/414113 [00:12<01:20, 4467.56it/s]\u001b[A\n",
      " 13%|█▎        | 53917/414113 [00:12<01:20, 4491.71it/s]\u001b[A\n",
      " 13%|█▎        | 54385/414113 [00:12<01:19, 4544.88it/s]\u001b[A\n",
      " 13%|█▎        | 54840/414113 [00:12<01:19, 4505.59it/s]\u001b[A\n",
      " 13%|█▎        | 55291/414113 [00:13<01:19, 4499.28it/s]\u001b[A\n",
      " 13%|█▎        | 55742/414113 [00:13<01:19, 4496.69it/s]\u001b[A\n",
      " 14%|█▎        | 56200/414113 [00:13<01:19, 4520.93it/s]\u001b[A\n",
      " 14%|█▎        | 56653/414113 [00:13<01:19, 4522.66it/s]\u001b[A\n",
      " 14%|█▍        | 57106/414113 [00:13<01:19, 4516.23it/s]\u001b[A\n",
      " 14%|█▍        | 57558/414113 [00:13<01:19, 4509.82it/s]\u001b[A\n",
      " 14%|█▍        | 58010/414113 [00:13<01:20, 4437.24it/s]\u001b[A\n",
      " 14%|█▍        | 58459/414113 [00:13<01:19, 4451.09it/s]\u001b[A\n",
      " 14%|█▍        | 58915/414113 [00:13<01:19, 4481.82it/s]\u001b[A\n",
      " 14%|█▍        | 59364/414113 [00:13<01:19, 4450.23it/s]\u001b[A\n",
      " 14%|█▍        | 59817/414113 [00:14<01:19, 4471.39it/s]\u001b[A\n",
      " 15%|█▍        | 60265/414113 [00:14<01:20, 4393.41it/s]\u001b[A\n",
      " 15%|█▍        | 60726/414113 [00:14<01:19, 4455.09it/s]\u001b[A\n",
      " 15%|█▍        | 61197/414113 [00:14<01:17, 4528.48it/s]\u001b[A\n",
      " 15%|█▍        | 61657/414113 [00:14<01:17, 4547.37it/s]\u001b[A\n",
      " 15%|█▍        | 62113/414113 [00:14<01:18, 4499.28it/s]\u001b[A\n",
      " 15%|█▌        | 62564/414113 [00:14<01:18, 4473.08it/s]\u001b[A\n",
      " 15%|█▌        | 63012/414113 [00:14<01:26, 4042.93it/s]\u001b[A\n",
      " 15%|█▌        | 63425/414113 [00:14<01:28, 3958.85it/s]\u001b[A\n",
      " 15%|█▌        | 63847/414113 [00:15<01:26, 4031.38it/s]\u001b[A\n",
      " 16%|█▌        | 64280/414113 [00:15<01:25, 4115.36it/s]\u001b[A\n",
      " 16%|█▌        | 64747/414113 [00:15<01:21, 4266.29it/s]\u001b[A\n",
      " 16%|█▌        | 65206/414113 [00:15<01:20, 4357.16it/s]\u001b[A\n",
      " 16%|█▌        | 65645/414113 [00:15<01:20, 4310.24it/s]\u001b[A\n",
      " 16%|█▌        | 66094/414113 [00:15<01:19, 4360.94it/s]\u001b[A\n",
      " 16%|█▌        | 66532/414113 [00:15<01:19, 4363.09it/s]\u001b[A\n",
      " 16%|█▌        | 66993/414113 [00:15<01:18, 4433.49it/s]\u001b[A\n",
      " 16%|█▋        | 67438/414113 [00:15<01:18, 4423.29it/s]\u001b[A\n",
      " 16%|█▋        | 67882/414113 [00:15<01:19, 4366.73it/s]\u001b[A\n",
      " 16%|█▋        | 68320/414113 [00:16<01:19, 4353.20it/s]\u001b[A\n",
      " 17%|█▋        | 68756/414113 [00:16<01:19, 4337.03it/s]\u001b[A\n",
      " 17%|█▋        | 69211/414113 [00:16<01:18, 4396.86it/s]\u001b[A\n",
      " 17%|█▋        | 69653/414113 [00:16<01:18, 4402.14it/s]\u001b[A\n",
      " 17%|█▋        | 70094/414113 [00:16<01:18, 4378.66it/s]\u001b[A\n",
      " 17%|█▋        | 70551/414113 [00:16<01:17, 4430.57it/s]\u001b[A\n",
      " 17%|█▋        | 70995/414113 [00:16<01:17, 4417.07it/s]\u001b[A\n",
      " 17%|█▋        | 71437/414113 [00:16<01:20, 4262.63it/s]\u001b[A\n",
      " 17%|█▋        | 71889/414113 [00:16<01:18, 4335.80it/s]\u001b[A\n",
      " 17%|█▋        | 72324/414113 [00:16<01:19, 4319.48it/s]\u001b[A\n",
      " 18%|█▊        | 72757/414113 [00:17<01:19, 4319.26it/s]\u001b[A\n",
      " 18%|█▊        | 73190/414113 [00:17<01:18, 4320.55it/s]\u001b[A\n",
      " 18%|█▊        | 73638/414113 [00:17<01:17, 4366.24it/s]\u001b[A\n",
      " 18%|█▊        | 74076/414113 [00:17<01:18, 4345.80it/s]\u001b[A\n",
      " 18%|█▊        | 74512/414113 [00:17<01:18, 4349.03it/s]\u001b[A\n",
      " 18%|█▊        | 74951/414113 [00:17<01:17, 4360.62it/s]\u001b[A\n",
      " 18%|█▊        | 75388/414113 [00:17<01:17, 4344.67it/s]\u001b[A\n",
      " 18%|█▊        | 75828/414113 [00:17<01:17, 4360.55it/s]\u001b[A\n",
      " 18%|█▊        | 76273/414113 [00:17<01:17, 4386.32it/s]\u001b[A\n",
      " 19%|█▊        | 76712/414113 [00:17<01:16, 4385.70it/s]\u001b[A\n",
      " 19%|█▊        | 77151/414113 [00:18<01:16, 4377.91it/s]\u001b[A\n",
      " 19%|█▊        | 77598/414113 [00:18<01:16, 4404.06it/s]\u001b[A\n",
      " 19%|█▉        | 78057/414113 [00:18<01:15, 4456.50it/s]\u001b[A\n",
      " 19%|█▉        | 78516/414113 [00:18<01:14, 4495.25it/s]\u001b[A\n",
      " 19%|█▉        | 78966/414113 [00:18<01:15, 4455.45it/s]\u001b[A\n",
      " 19%|█▉        | 79425/414113 [00:18<01:14, 4492.50it/s]\u001b[A\n",
      " 19%|█▉        | 79875/414113 [00:18<01:14, 4487.02it/s]\u001b[A\n",
      " 19%|█▉        | 80324/414113 [00:18<01:14, 4471.62it/s]\u001b[A\n",
      " 20%|█▉        | 80772/414113 [00:18<01:14, 4467.52it/s]\u001b[A\n",
      " 20%|█▉        | 81219/414113 [00:18<01:15, 4415.68it/s]\u001b[A\n",
      " 20%|█▉        | 81661/414113 [00:19<01:15, 4393.34it/s]\u001b[A\n",
      " 20%|█▉        | 82101/414113 [00:19<01:16, 4355.70it/s]\u001b[A\n",
      " 20%|█▉        | 82546/414113 [00:19<01:15, 4381.88it/s]\u001b[A\n",
      " 20%|██        | 82993/414113 [00:19<01:15, 4405.87it/s]\u001b[A\n",
      " 20%|██        | 83434/414113 [00:19<01:15, 4356.68it/s]\u001b[A\n",
      " 20%|██        | 83884/414113 [00:19<01:15, 4397.63it/s]\u001b[A\n",
      " 20%|██        | 84325/414113 [00:19<01:16, 4322.33it/s]\u001b[A\n",
      " 20%|██        | 84776/414113 [00:19<01:15, 4375.13it/s]\u001b[A\n",
      " 21%|██        | 85233/414113 [00:19<01:14, 4430.79it/s]\u001b[A\n",
      " 21%|██        | 85677/414113 [00:19<01:15, 4377.86it/s]\u001b[A\n",
      " 21%|██        | 86116/414113 [00:20<01:15, 4362.86it/s]\u001b[A\n",
      " 21%|██        | 86572/414113 [00:20<01:14, 4418.81it/s]\u001b[A\n",
      " 21%|██        | 87031/414113 [00:20<01:13, 4468.28it/s]\u001b[A\n",
      " 21%|██        | 87479/414113 [00:20<01:13, 4430.15it/s]\u001b[A\n",
      " 21%|██        | 87942/414113 [00:20<01:12, 4486.50it/s]\u001b[A\n",
      " 21%|██▏       | 88406/414113 [00:20<01:11, 4529.31it/s]\u001b[A\n",
      " 21%|██▏       | 88860/414113 [00:20<01:12, 4517.31it/s]\u001b[A\n",
      " 22%|██▏       | 89320/414113 [00:20<01:11, 4539.12it/s]\u001b[A\n",
      " 22%|██▏       | 89775/414113 [00:20<01:11, 4520.27it/s]\u001b[A\n",
      " 22%|██▏       | 90228/414113 [00:20<01:12, 4458.64it/s]\u001b[A\n",
      " 22%|██▏       | 90675/414113 [00:21<01:13, 4406.79it/s]\u001b[A\n",
      " 22%|██▏       | 91121/414113 [00:21<01:13, 4421.66it/s]\u001b[A\n",
      " 22%|██▏       | 91572/414113 [00:21<01:12, 4447.13it/s]\u001b[A\n",
      " 22%|██▏       | 92018/414113 [00:21<01:12, 4450.89it/s]\u001b[A\n",
      " 22%|██▏       | 92485/414113 [00:21<01:11, 4513.17it/s]\u001b[A\n",
      " 22%|██▏       | 92941/414113 [00:21<01:10, 4526.01it/s]\u001b[A\n",
      " 23%|██▎       | 93401/414113 [00:21<01:10, 4547.73it/s]\u001b[A\n",
      " 23%|██▎       | 93856/414113 [00:21<01:10, 4544.98it/s]\u001b[A\n",
      " 23%|██▎       | 94316/414113 [00:21<01:10, 4561.30it/s]\u001b[A\n",
      " 23%|██▎       | 94773/414113 [00:21<01:10, 4537.15it/s]\u001b[A\n",
      " 23%|██▎       | 95227/414113 [00:22<01:11, 4488.59it/s]\u001b[A\n",
      " 23%|██▎       | 95677/414113 [00:22<01:11, 4457.96it/s]\u001b[A\n",
      " 23%|██▎       | 96123/414113 [00:22<01:12, 4413.37it/s]\u001b[A\n",
      " 23%|██▎       | 96577/414113 [00:22<01:11, 4447.94it/s]\u001b[A\n",
      " 23%|██▎       | 97039/414113 [00:22<01:10, 4496.76it/s]\u001b[A\n",
      " 24%|██▎       | 97508/414113 [00:22<01:09, 4552.38it/s]\u001b[A\n",
      " 24%|██▎       | 97969/414113 [00:22<01:09, 4568.95it/s]\u001b[A\n",
      " 24%|██▍       | 98427/414113 [00:22<01:09, 4562.65it/s]\u001b[A\n",
      " 24%|██▍       | 98884/414113 [00:22<01:09, 4538.70it/s]\u001b[A\n",
      " 24%|██▍       | 99339/414113 [00:23<01:09, 4517.24it/s]\u001b[A\n",
      " 24%|██▍       | 99791/414113 [00:23<01:09, 4495.25it/s]\u001b[A\n",
      " 24%|██▍       | 100241/414113 [00:23<01:09, 4488.64it/s]\u001b[A\n",
      " 24%|██▍       | 100690/414113 [00:23<01:10, 4444.40it/s]\u001b[A\n",
      " 24%|██▍       | 101135/414113 [00:23<01:15, 4158.59it/s]\u001b[A\n",
      " 25%|██▍       | 101588/414113 [00:23<01:13, 4262.72it/s]\u001b[A\n",
      " 25%|██▍       | 102043/414113 [00:23<01:11, 4341.93it/s]\u001b[A\n",
      " 25%|██▍       | 102488/414113 [00:23<01:11, 4371.17it/s]\u001b[A\n",
      " 25%|██▍       | 102933/414113 [00:23<01:10, 4394.25it/s]\u001b[A\n",
      " 25%|██▍       | 103376/414113 [00:23<01:10, 4402.38it/s]\u001b[A\n",
      " 25%|██▌       | 103826/414113 [00:24<01:10, 4430.02it/s]\u001b[A\n",
      " 25%|██▌       | 104270/414113 [00:24<01:10, 4370.56it/s]\u001b[A\n",
      " 25%|██▌       | 104721/414113 [00:24<01:10, 4408.88it/s]\u001b[A\n",
      " 25%|██▌       | 105167/414113 [00:24<01:09, 4423.01it/s]\u001b[A\n",
      " 26%|██▌       | 105610/414113 [00:24<01:09, 4415.07it/s]\u001b[A\n",
      " 26%|██▌       | 106079/414113 [00:24<01:08, 4491.89it/s]\u001b[A\n",
      " 26%|██▌       | 106532/414113 [00:24<01:08, 4500.96it/s]\u001b[A\n",
      " 26%|██▌       | 106983/414113 [00:24<01:08, 4475.60it/s]\u001b[A\n",
      " 26%|██▌       | 107435/414113 [00:24<01:08, 4487.04it/s]\u001b[A\n",
      " 26%|██▌       | 107884/414113 [00:24<01:08, 4443.90it/s]\u001b[A\n",
      " 26%|██▌       | 108329/414113 [00:25<01:09, 4426.14it/s]\u001b[A\n",
      " 26%|██▋       | 108779/414113 [00:25<01:08, 4446.97it/s]\u001b[A\n",
      " 26%|██▋       | 109224/414113 [00:25<01:08, 4418.71it/s]\u001b[A\n",
      " 26%|██▋       | 109678/414113 [00:25<01:08, 4452.77it/s]\u001b[A\n",
      " 27%|██▋       | 110124/414113 [00:25<01:09, 4383.47it/s]\u001b[A\n",
      " 27%|██▋       | 110596/414113 [00:25<01:07, 4477.13it/s]\u001b[A\n",
      " 27%|██▋       | 111049/414113 [00:25<01:07, 4492.00it/s]\u001b[A\n",
      " 27%|██▋       | 111503/414113 [00:25<01:07, 4505.03it/s]\u001b[A\n",
      " 27%|██▋       | 111960/414113 [00:25<01:06, 4524.26it/s]\u001b[A\n",
      " 27%|██▋       | 112413/414113 [00:25<01:08, 4395.98it/s]\u001b[A\n",
      " 27%|██▋       | 112854/414113 [00:26<01:09, 4329.16it/s]\u001b[A\n",
      " 27%|██▋       | 113288/414113 [00:26<01:09, 4301.24it/s]\u001b[A\n",
      " 27%|██▋       | 113719/414113 [00:26<01:10, 4283.41it/s]\u001b[A\n",
      " 28%|██▊       | 114148/414113 [00:26<01:10, 4284.45it/s]\u001b[A\n",
      " 28%|██▊       | 114580/414113 [00:26<01:09, 4294.75it/s]\u001b[A\n",
      " 28%|██▊       | 115014/414113 [00:26<01:09, 4307.03it/s]\u001b[A\n",
      " 28%|██▊       | 115445/414113 [00:26<01:09, 4299.91it/s]\u001b[A\n",
      " 28%|██▊       | 115901/414113 [00:26<01:08, 4373.01it/s]\u001b[A\n",
      " 28%|██▊       | 116354/414113 [00:26<01:07, 4416.33it/s]\u001b[A\n",
      " 28%|██▊       | 116797/414113 [00:26<01:07, 4402.10it/s]\u001b[A\n",
      " 28%|██▊       | 117238/414113 [00:27<01:07, 4396.03it/s]\u001b[A\n",
      " 28%|██▊       | 117682/414113 [00:27<01:07, 4408.59it/s]\u001b[A\n",
      " 29%|██▊       | 118124/414113 [00:27<01:07, 4381.77it/s]\u001b[A\n",
      " 29%|██▊       | 118563/414113 [00:27<01:07, 4381.54it/s]\u001b[A\n",
      " 29%|██▊       | 119002/414113 [00:27<01:07, 4364.56it/s]\u001b[A\n",
      " 29%|██▉       | 119455/414113 [00:27<01:06, 4412.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 119907/414113 [00:27<01:06, 4443.68it/s]\u001b[A\n",
      " 29%|██▉       | 120357/414113 [00:27<01:05, 4460.34it/s]\u001b[A\n",
      " 29%|██▉       | 120804/414113 [00:27<01:05, 4450.02it/s]\u001b[A\n",
      " 29%|██▉       | 121260/414113 [00:27<01:05, 4480.16it/s]\u001b[A\n",
      " 29%|██▉       | 121709/414113 [00:28<01:05, 4440.18it/s]\u001b[A\n",
      " 29%|██▉       | 122155/414113 [00:28<01:05, 4445.46it/s]\u001b[A\n",
      " 30%|██▉       | 122604/414113 [00:28<01:05, 4455.84it/s]\u001b[A\n",
      " 30%|██▉       | 123050/414113 [00:28<01:05, 4439.65it/s]\u001b[A\n",
      " 30%|██▉       | 123495/414113 [00:28<01:05, 4438.18it/s]\u001b[A\n",
      " 30%|██▉       | 123939/414113 [00:28<01:05, 4414.86it/s]\u001b[A\n",
      " 30%|███       | 124381/414113 [00:28<02:01, 2378.82it/s]\u001b[A\n",
      " 30%|███       | 124804/414113 [00:29<01:45, 2738.18it/s]\u001b[A\n",
      " 30%|███       | 125265/414113 [00:29<01:32, 3117.53it/s]\u001b[A\n",
      " 30%|███       | 125718/414113 [00:29<01:23, 3438.50it/s]\u001b[A\n",
      " 30%|███       | 126179/414113 [00:29<01:17, 3719.58it/s]\u001b[A\n",
      " 31%|███       | 126627/414113 [00:29<01:13, 3919.11it/s]\u001b[A\n",
      " 31%|███       | 127078/414113 [00:29<01:10, 4077.40it/s]\u001b[A\n",
      " 31%|███       | 127531/414113 [00:29<01:08, 4200.96it/s]\u001b[A\n",
      " 31%|███       | 127975/414113 [00:29<01:07, 4268.03it/s]\u001b[A\n",
      " 31%|███       | 128435/414113 [00:29<01:05, 4362.17it/s]\u001b[A\n",
      " 31%|███       | 128886/414113 [00:29<01:04, 4404.36it/s]\u001b[A\n",
      " 31%|███       | 129336/414113 [00:30<01:04, 4430.95it/s]\u001b[A\n",
      " 31%|███▏      | 129816/414113 [00:30<01:02, 4534.65it/s]\u001b[A\n",
      " 31%|███▏      | 130275/414113 [00:30<01:03, 4496.37it/s]\u001b[A\n",
      " 32%|███▏      | 130728/414113 [00:30<01:03, 4451.84it/s]\u001b[A\n",
      " 32%|███▏      | 131176/414113 [00:30<01:03, 4456.60it/s]\u001b[A\n",
      " 32%|███▏      | 131633/414113 [00:30<01:02, 4487.58it/s]\u001b[A\n",
      " 32%|███▏      | 132084/414113 [00:30<01:02, 4478.66it/s]\u001b[A\n",
      " 32%|███▏      | 132533/414113 [00:30<01:02, 4478.56it/s]\u001b[A\n",
      " 32%|███▏      | 132982/414113 [00:30<01:03, 4434.57it/s]\u001b[A\n",
      " 32%|███▏      | 133426/414113 [00:30<01:04, 4373.25it/s]\u001b[A\n",
      " 32%|███▏      | 133864/414113 [00:31<01:04, 4356.16it/s]\u001b[A\n",
      " 32%|███▏      | 134301/414113 [00:31<01:05, 4296.07it/s]\u001b[A\n",
      " 33%|███▎      | 134732/414113 [00:31<01:05, 4255.77it/s]\u001b[A\n",
      " 33%|███▎      | 135159/414113 [00:31<01:05, 4258.93it/s]\u001b[A\n",
      " 33%|███▎      | 135626/414113 [00:31<01:03, 4371.47it/s]\u001b[A\n",
      " 33%|███▎      | 136081/414113 [00:31<01:02, 4420.67it/s]\u001b[A\n",
      " 33%|███▎      | 136541/414113 [00:31<01:02, 4471.10it/s]\u001b[A\n",
      " 33%|███▎      | 137011/414113 [00:31<01:01, 4536.43it/s]\u001b[A\n",
      " 33%|███▎      | 137466/414113 [00:31<01:01, 4485.79it/s]\u001b[A\n",
      " 33%|███▎      | 137923/414113 [00:32<01:01, 4508.28it/s]\u001b[A\n",
      " 33%|███▎      | 138375/414113 [00:32<01:01, 4470.75it/s]\u001b[A\n",
      " 34%|███▎      | 138823/414113 [00:32<01:01, 4467.82it/s]\u001b[A\n",
      " 34%|███▎      | 139272/414113 [00:32<01:01, 4473.92it/s]\u001b[A\n",
      " 34%|███▎      | 139722/414113 [00:32<01:01, 4481.09it/s]\u001b[A\n",
      " 34%|███▍      | 140171/414113 [00:32<01:01, 4482.67it/s]\u001b[A\n",
      " 34%|███▍      | 140630/414113 [00:32<01:00, 4514.17it/s]\u001b[A\n",
      " 34%|███▍      | 141085/414113 [00:32<01:00, 4523.02it/s]\u001b[A\n",
      " 34%|███▍      | 141539/414113 [00:32<01:00, 4527.23it/s]\u001b[A\n",
      " 34%|███▍      | 141992/414113 [00:32<01:00, 4478.08it/s]\u001b[A\n",
      " 34%|███▍      | 142440/414113 [00:33<01:01, 4435.20it/s]\u001b[A\n",
      " 35%|███▍      | 142885/414113 [00:33<01:01, 4437.99it/s]\u001b[A\n",
      " 35%|███▍      | 143329/414113 [00:33<01:01, 4407.86it/s]\u001b[A\n",
      " 35%|███▍      | 143777/414113 [00:33<01:01, 4428.89it/s]\u001b[A\n",
      " 35%|███▍      | 144228/414113 [00:33<01:00, 4451.85it/s]\u001b[A\n",
      " 35%|███▍      | 144699/414113 [00:33<00:59, 4524.20it/s]\u001b[A\n",
      " 35%|███▌      | 145153/414113 [00:33<00:59, 4528.51it/s]\u001b[A\n",
      " 35%|███▌      | 145619/414113 [00:33<00:58, 4565.21it/s]\u001b[A\n",
      " 35%|███▌      | 146076/414113 [00:33<01:01, 4346.04it/s]\u001b[A\n",
      " 35%|███▌      | 146513/414113 [00:33<01:01, 4352.89it/s]\u001b[A\n",
      " 35%|███▌      | 146954/414113 [00:34<01:01, 4369.71it/s]\u001b[A\n",
      " 36%|███▌      | 147397/414113 [00:34<01:00, 4386.03it/s]\u001b[A\n",
      " 36%|███▌      | 147837/414113 [00:34<01:00, 4375.40it/s]\u001b[A\n",
      " 36%|███▌      | 148298/414113 [00:34<00:59, 4442.40it/s]\u001b[A\n",
      " 36%|███▌      | 148755/414113 [00:34<00:59, 4477.58it/s]\u001b[A\n",
      " 36%|███▌      | 149230/414113 [00:34<00:58, 4555.37it/s]\u001b[A\n",
      " 36%|███▌      | 149688/414113 [00:34<00:57, 4562.24it/s]\u001b[A\n",
      " 36%|███▋      | 150153/414113 [00:34<00:57, 4586.66it/s]\u001b[A\n",
      " 36%|███▋      | 150625/414113 [00:34<00:56, 4625.22it/s]\u001b[A\n",
      " 36%|███▋      | 151088/414113 [00:34<00:57, 4591.87it/s]\u001b[A\n",
      " 37%|███▋      | 151548/414113 [00:35<00:57, 4549.91it/s]\u001b[A\n",
      " 37%|███▋      | 152004/414113 [00:35<00:57, 4544.57it/s]\u001b[A\n",
      " 37%|███▋      | 152466/414113 [00:35<00:57, 4565.81it/s]\u001b[A\n",
      " 37%|███▋      | 152941/414113 [00:35<00:56, 4619.36it/s]\u001b[A\n",
      " 37%|███▋      | 153404/414113 [00:35<00:56, 4618.75it/s]\u001b[A\n",
      " 37%|███▋      | 153875/414113 [00:35<00:56, 4643.33it/s]\u001b[A\n",
      " 37%|███▋      | 154340/414113 [00:35<00:56, 4631.14it/s]\u001b[A\n",
      " 37%|███▋      | 154804/414113 [00:35<00:56, 4586.55it/s]\u001b[A\n",
      " 37%|███▋      | 155270/414113 [00:35<00:56, 4607.14it/s]\u001b[A\n",
      " 38%|███▊      | 155731/414113 [00:35<00:57, 4525.12it/s]\u001b[A\n",
      " 38%|███▊      | 156184/414113 [00:36<00:57, 4488.82it/s]\u001b[A\n",
      " 38%|███▊      | 156652/414113 [00:36<00:56, 4543.59it/s]\u001b[A\n",
      " 38%|███▊      | 157107/414113 [00:36<00:56, 4542.41it/s]\u001b[A\n",
      " 38%|███▊      | 157564/414113 [00:36<00:56, 4549.72it/s]\u001b[A\n",
      " 38%|███▊      | 158020/414113 [00:36<00:56, 4510.50it/s]\u001b[A\n",
      " 38%|███▊      | 158472/414113 [00:36<00:57, 4480.53it/s]\u001b[A\n",
      " 38%|███▊      | 158921/414113 [00:36<00:57, 4426.72it/s]\u001b[A\n",
      " 38%|███▊      | 159376/414113 [00:36<00:57, 4462.74it/s]\u001b[A\n",
      " 39%|███▊      | 159823/414113 [00:36<01:01, 4125.08it/s]\u001b[A\n",
      " 39%|███▊      | 160256/414113 [00:36<01:00, 4184.32it/s]\u001b[A\n",
      " 39%|███▉      | 160694/414113 [00:37<00:59, 4240.71it/s]\u001b[A\n",
      " 39%|███▉      | 161152/414113 [00:37<00:58, 4336.56it/s]\u001b[A\n",
      " 39%|███▉      | 161593/414113 [00:37<00:57, 4355.48it/s]\u001b[A\n",
      " 39%|███▉      | 162039/414113 [00:37<00:57, 4385.07it/s]\u001b[A\n",
      " 39%|███▉      | 162492/414113 [00:37<00:56, 4427.36it/s]\u001b[A\n",
      " 39%|███▉      | 162943/414113 [00:37<00:56, 4449.51it/s]\u001b[A\n",
      " 39%|███▉      | 163405/414113 [00:37<00:55, 4497.51it/s]\u001b[A\n",
      " 40%|███▉      | 163856/414113 [00:37<00:55, 4493.36it/s]\u001b[A\n",
      " 40%|███▉      | 164306/414113 [00:37<00:56, 4420.52it/s]\u001b[A\n",
      " 40%|███▉      | 164750/414113 [00:38<00:56, 4423.86it/s]\u001b[A\n",
      " 40%|███▉      | 165193/414113 [00:38<00:56, 4374.06it/s]\u001b[A\n",
      " 40%|███▉      | 165633/414113 [00:38<00:56, 4381.60it/s]\u001b[A\n",
      " 40%|████      | 166072/414113 [00:38<00:57, 4343.23it/s]\u001b[A\n",
      " 40%|████      | 166507/414113 [00:38<00:57, 4317.32it/s]\u001b[A\n",
      " 40%|████      | 166963/414113 [00:38<00:56, 4385.80it/s]\u001b[A\n",
      " 40%|████      | 167417/414113 [00:38<00:55, 4428.46it/s]\u001b[A\n",
      " 41%|████      | 167861/414113 [00:38<00:55, 4423.14it/s]\u001b[A\n",
      " 41%|████      | 168304/414113 [00:38<00:55, 4402.81it/s]\u001b[A\n",
      " 41%|████      | 168745/414113 [00:38<00:55, 4399.91it/s]\u001b[A\n",
      " 41%|████      | 169186/414113 [00:39<00:56, 4345.68it/s]\u001b[A\n",
      " 41%|████      | 169621/414113 [00:39<00:56, 4323.28it/s]\u001b[A\n",
      " 41%|████      | 170060/414113 [00:39<00:56, 4341.19it/s]\u001b[A\n",
      " 41%|████      | 170506/414113 [00:39<00:55, 4373.84it/s]\u001b[A\n",
      " 41%|████▏     | 170944/414113 [00:39<00:55, 4363.13it/s]\u001b[A\n",
      " 41%|████▏     | 171388/414113 [00:39<00:55, 4385.64it/s]\u001b[A\n",
      " 41%|████▏     | 171838/414113 [00:39<00:54, 4417.40it/s]\u001b[A\n",
      " 42%|████▏     | 172295/414113 [00:39<00:54, 4459.94it/s]\u001b[A\n",
      " 42%|████▏     | 172758/414113 [00:39<00:53, 4508.72it/s]\u001b[A\n",
      " 42%|████▏     | 173210/414113 [00:39<00:54, 4429.63it/s]\u001b[A\n",
      " 42%|████▏     | 173658/414113 [00:40<00:54, 4442.18it/s]\u001b[A\n",
      " 42%|████▏     | 174103/414113 [00:40<00:54, 4394.17it/s]\u001b[A\n",
      " 42%|████▏     | 174543/414113 [00:40<00:54, 4367.14it/s]\u001b[A\n",
      " 42%|████▏     | 174988/414113 [00:40<00:54, 4389.19it/s]\u001b[A\n",
      " 42%|████▏     | 175434/414113 [00:40<00:54, 4410.18it/s]\u001b[A\n",
      " 42%|████▏     | 175882/414113 [00:40<00:53, 4428.59it/s]\u001b[A\n",
      " 43%|████▎     | 176326/414113 [00:40<00:53, 4429.67it/s]\u001b[A\n",
      " 43%|████▎     | 176777/414113 [00:40<00:53, 4453.19it/s]\u001b[A\n",
      " 43%|████▎     | 177227/414113 [00:40<00:53, 4464.13it/s]\u001b[A\n",
      " 43%|████▎     | 177674/414113 [00:40<00:53, 4411.99it/s]\u001b[A\n",
      " 43%|████▎     | 178116/414113 [00:41<00:53, 4379.70it/s]\u001b[A\n",
      " 43%|████▎     | 178555/414113 [00:41<00:53, 4362.47it/s]\u001b[A\n",
      " 43%|████▎     | 179004/414113 [00:41<00:53, 4397.24it/s]\u001b[A\n",
      " 43%|████▎     | 179456/414113 [00:41<00:52, 4430.47it/s]\u001b[A\n",
      " 43%|████▎     | 179910/414113 [00:41<00:52, 4460.64it/s]\u001b[A\n",
      " 44%|████▎     | 180357/414113 [00:41<00:52, 4423.65it/s]\u001b[A\n",
      " 44%|████▎     | 180810/414113 [00:41<00:52, 4454.92it/s]\u001b[A\n",
      " 44%|████▍     | 181256/414113 [00:41<00:52, 4445.39it/s]\u001b[A\n",
      " 44%|████▍     | 181711/414113 [00:41<00:51, 4474.20it/s]\u001b[A\n",
      " 44%|████▍     | 182159/414113 [00:41<00:52, 4413.93it/s]\u001b[A\n",
      " 44%|████▍     | 182601/414113 [00:42<00:52, 4388.34it/s]\u001b[A\n",
      " 44%|████▍     | 183057/414113 [00:42<00:52, 4436.08it/s]\u001b[A\n",
      " 44%|████▍     | 183511/414113 [00:42<00:51, 4464.04it/s]\u001b[A\n",
      " 44%|████▍     | 183958/414113 [00:42<00:51, 4463.02it/s]\u001b[A\n",
      " 45%|████▍     | 184406/414113 [00:42<00:51, 4466.03it/s]\u001b[A\n",
      " 45%|████▍     | 184862/414113 [00:42<00:51, 4493.26it/s]\u001b[A\n",
      " 45%|████▍     | 185322/414113 [00:42<00:50, 4523.78it/s]\u001b[A\n",
      " 45%|████▍     | 185775/414113 [00:42<00:50, 4518.98it/s]\u001b[A\n",
      " 45%|████▍     | 186227/414113 [00:42<00:50, 4513.29it/s]\u001b[A\n",
      " 45%|████▌     | 186679/414113 [00:42<00:50, 4487.62it/s]\u001b[A\n",
      " 45%|████▌     | 187128/414113 [00:43<00:50, 4469.68it/s]\u001b[A\n",
      " 45%|████▌     | 187576/414113 [00:43<00:51, 4422.60it/s]\u001b[A\n",
      " 45%|████▌     | 188019/414113 [00:43<00:51, 4409.57it/s]\u001b[A\n",
      " 46%|████▌     | 188464/414113 [00:43<00:51, 4420.40it/s]\u001b[A\n",
      " 46%|████▌     | 188907/414113 [00:43<00:50, 4420.48it/s]\u001b[A\n",
      " 46%|████▌     | 189354/414113 [00:43<00:50, 4432.28it/s]\u001b[A\n",
      " 46%|████▌     | 189808/414113 [00:43<00:50, 4463.96it/s]\u001b[A\n",
      " 46%|████▌     | 190255/414113 [00:43<00:50, 4461.47it/s]\u001b[A\n",
      " 46%|████▌     | 190712/414113 [00:43<00:49, 4491.07it/s]\u001b[A\n",
      " 46%|████▌     | 191162/414113 [00:43<00:49, 4488.60it/s]\u001b[A\n",
      " 46%|████▋     | 191611/414113 [00:44<00:49, 4484.09it/s]\u001b[A\n",
      " 46%|████▋     | 192066/414113 [00:44<00:49, 4502.26it/s]\u001b[A\n",
      " 46%|████▋     | 192520/414113 [00:44<00:49, 4511.64it/s]\u001b[A\n",
      " 47%|████▋     | 192972/414113 [00:44<00:49, 4505.04it/s]\u001b[A\n",
      " 47%|████▋     | 193425/414113 [00:44<00:48, 4510.62it/s]\u001b[A\n",
      " 47%|████▋     | 193888/414113 [00:44<00:48, 4544.47it/s]\u001b[A\n",
      " 47%|████▋     | 194343/414113 [00:44<00:48, 4503.16it/s]\u001b[A\n",
      " 47%|████▋     | 194804/414113 [00:44<00:48, 4532.02it/s]\u001b[A\n",
      " 47%|████▋     | 195261/414113 [00:44<00:48, 4542.36it/s]\u001b[A\n",
      " 47%|████▋     | 195716/414113 [00:44<00:48, 4499.54it/s]\u001b[A\n",
      " 47%|████▋     | 196167/414113 [00:45<00:49, 4446.56it/s]\u001b[A\n",
      " 47%|████▋     | 196613/414113 [00:45<00:48, 4448.48it/s]\u001b[A\n",
      " 48%|████▊     | 197059/414113 [00:45<00:48, 4442.32it/s]\u001b[A\n",
      " 48%|████▊     | 197511/414113 [00:45<00:48, 4463.97it/s]\u001b[A\n",
      " 48%|████▊     | 197977/414113 [00:45<00:47, 4519.76it/s]\u001b[A\n",
      " 48%|████▊     | 198430/414113 [00:45<00:47, 4517.91it/s]\u001b[A\n",
      " 48%|████▊     | 198882/414113 [00:45<00:47, 4504.31it/s]\u001b[A\n",
      " 48%|████▊     | 199341/414113 [00:45<00:47, 4527.65it/s]\u001b[A\n",
      " 48%|████▊     | 199794/414113 [00:45<00:47, 4526.73it/s]\u001b[A\n",
      " 48%|████▊     | 200247/414113 [00:45<00:47, 4499.89it/s]\u001b[A\n",
      " 48%|████▊     | 200698/414113 [00:46<00:48, 4442.46it/s]\u001b[A\n",
      " 49%|████▊     | 201156/414113 [00:46<00:47, 4481.70it/s]\u001b[A\n",
      " 49%|████▊     | 201610/414113 [00:46<00:47, 4498.26it/s]\u001b[A\n",
      " 49%|████▉     | 202061/414113 [00:46<00:47, 4471.74it/s]\u001b[A\n",
      " 49%|████▉     | 202509/414113 [00:46<00:47, 4447.26it/s]\u001b[A\n",
      " 49%|████▉     | 202954/414113 [00:46<00:47, 4427.45it/s]\u001b[A\n",
      " 49%|████▉     | 203397/414113 [00:46<00:47, 4415.24it/s]\u001b[A\n",
      " 49%|████▉     | 203846/414113 [00:46<00:47, 4437.12it/s]\u001b[A\n",
      " 49%|████▉     | 204293/414113 [00:46<00:47, 4445.97it/s]\u001b[A\n",
      " 49%|████▉     | 204738/414113 [00:47<00:47, 4402.86it/s]\u001b[A\n",
      " 50%|████▉     | 205179/414113 [00:47<00:48, 4345.83it/s]\u001b[A\n",
      " 50%|████▉     | 205616/414113 [00:47<00:47, 4349.91it/s]\u001b[A\n",
      " 50%|████▉     | 206052/414113 [00:47<00:48, 4323.91it/s]\u001b[A\n",
      " 50%|████▉     | 206485/414113 [00:47<00:48, 4323.46it/s]\u001b[A\n",
      " 50%|████▉     | 206923/414113 [00:47<00:47, 4337.87it/s]\u001b[A\n",
      " 50%|█████     | 207363/414113 [00:47<00:47, 4353.85it/s]\u001b[A\n",
      " 50%|█████     | 207819/414113 [00:47<00:46, 4413.34it/s]\u001b[A\n",
      " 50%|█████     | 208264/414113 [00:47<00:46, 4423.29it/s]\u001b[A\n",
      " 50%|█████     | 208707/414113 [00:47<00:46, 4423.62it/s]\u001b[A\n",
      " 51%|█████     | 209152/414113 [00:48<00:46, 4429.47it/s]\u001b[A\n",
      " 51%|█████     | 209596/414113 [00:48<00:46, 4428.01it/s]\u001b[A\n",
      " 51%|█████     | 210054/414113 [00:48<00:45, 4470.54it/s]\u001b[A\n",
      " 51%|█████     | 210509/414113 [00:48<00:45, 4491.81it/s]\u001b[A\n",
      " 51%|█████     | 210959/414113 [00:48<00:45, 4434.63it/s]\u001b[A\n",
      " 51%|█████     | 211407/414113 [00:48<00:45, 4447.26it/s]\u001b[A\n",
      " 51%|█████     | 211857/414113 [00:48<00:45, 4461.32it/s]\u001b[A\n",
      " 51%|█████▏    | 212312/414113 [00:48<00:45, 4484.37it/s]\u001b[A\n",
      " 51%|█████▏    | 212761/414113 [00:48<00:44, 4474.73it/s]\u001b[A\n",
      " 51%|█████▏    | 213209/414113 [00:48<00:45, 4440.02it/s]\u001b[A\n",
      " 52%|█████▏    | 213654/414113 [00:49<00:45, 4427.98it/s]\u001b[A\n",
      " 52%|█████▏    | 214097/414113 [00:49<00:45, 4428.00it/s]\u001b[A\n",
      " 52%|█████▏    | 214556/414113 [00:49<00:44, 4475.10it/s]\u001b[A\n",
      " 52%|█████▏    | 215004/414113 [00:49<00:44, 4473.34it/s]\u001b[A\n",
      " 52%|█████▏    | 215456/414113 [00:49<00:44, 4485.09it/s]\u001b[A\n",
      " 52%|█████▏    | 215905/414113 [00:49<00:44, 4434.20it/s]\u001b[A\n",
      " 52%|█████▏    | 216349/414113 [00:49<00:44, 4433.41it/s]\u001b[A\n",
      " 52%|█████▏    | 216793/414113 [00:49<00:45, 4375.62it/s]\u001b[A\n",
      " 52%|█████▏    | 217231/414113 [00:49<00:50, 3888.76it/s]\u001b[A\n",
      " 53%|█████▎    | 217633/414113 [00:49<00:50, 3926.33it/s]\u001b[A\n",
      " 53%|█████▎    | 218058/414113 [00:50<00:48, 4017.19it/s]\u001b[A\n",
      " 53%|█████▎    | 218517/414113 [00:50<00:46, 4171.85it/s]\u001b[A\n",
      " 53%|█████▎    | 218974/414113 [00:50<00:45, 4281.78it/s]\u001b[A\n",
      " 53%|█████▎    | 219434/414113 [00:50<00:44, 4371.60it/s]\u001b[A\n",
      " 53%|█████▎    | 219899/414113 [00:50<00:43, 4450.16it/s]\u001b[A\n",
      " 53%|█████▎    | 220354/414113 [00:50<00:43, 4477.78it/s]\u001b[A\n",
      " 53%|█████▎    | 220816/414113 [00:50<00:42, 4516.95it/s]\u001b[A\n",
      " 53%|█████▎    | 221270/414113 [00:50<00:42, 4515.63it/s]\u001b[A\n",
      " 54%|█████▎    | 221723/414113 [00:50<00:42, 4501.46it/s]\u001b[A\n",
      " 54%|█████▎    | 222174/414113 [00:50<00:42, 4476.59it/s]\u001b[A\n",
      " 54%|█████▍    | 222623/414113 [00:51<00:42, 4454.39it/s]\u001b[A\n",
      " 54%|█████▍    | 223087/414113 [00:51<00:42, 4505.80it/s]\u001b[A\n",
      " 54%|█████▍    | 223539/414113 [00:51<00:42, 4451.40it/s]\u001b[A\n",
      " 54%|█████▍    | 223992/414113 [00:51<00:42, 4473.29it/s]\u001b[A\n",
      " 54%|█████▍    | 224440/414113 [00:51<00:43, 4405.39it/s]\u001b[A\n",
      " 54%|█████▍    | 224920/414113 [00:51<00:41, 4514.38it/s]\u001b[A\n",
      " 54%|█████▍    | 225382/414113 [00:51<00:41, 4544.26it/s]\u001b[A\n",
      " 55%|█████▍    | 225845/414113 [00:51<00:41, 4566.78it/s]\u001b[A\n",
      " 55%|█████▍    | 226303/414113 [00:51<00:42, 4424.15it/s]\u001b[A\n",
      " 55%|█████▍    | 226747/414113 [00:52<00:42, 4427.91it/s]\u001b[A\n",
      " 55%|█████▍    | 227191/414113 [00:52<00:42, 4417.58it/s]\u001b[A\n",
      " 55%|█████▍    | 227670/414113 [00:52<00:41, 4520.80it/s]\u001b[A\n",
      " 55%|█████▌    | 228127/414113 [00:52<00:41, 4534.53it/s]\u001b[A\n",
      " 55%|█████▌    | 228592/414113 [00:52<00:40, 4568.36it/s]\u001b[A\n",
      " 55%|█████▌    | 229050/414113 [00:52<00:40, 4565.20it/s]\u001b[A\n",
      " 55%|█████▌    | 229520/414113 [00:52<00:40, 4604.01it/s]\u001b[A\n",
      " 56%|█████▌    | 229981/414113 [00:52<00:40, 4588.42it/s]\u001b[A\n",
      " 56%|█████▌    | 230441/414113 [00:52<00:40, 4516.13it/s]\u001b[A\n",
      " 56%|█████▌    | 230894/414113 [00:52<00:41, 4464.87it/s]\u001b[A\n",
      " 56%|█████▌    | 231341/414113 [00:53<00:41, 4456.62it/s]\u001b[A\n",
      " 56%|█████▌    | 231787/414113 [00:53<00:41, 4392.87it/s]\u001b[A\n",
      " 56%|█████▌    | 232234/414113 [00:53<00:41, 4414.36it/s]\u001b[A\n",
      " 56%|█████▌    | 232676/414113 [00:53<00:41, 4359.14it/s]\u001b[A\n",
      " 56%|█████▋    | 233123/414113 [00:53<00:41, 4390.65it/s]\u001b[A\n",
      " 56%|█████▋    | 233575/414113 [00:53<00:40, 4428.26it/s]\u001b[A\n",
      " 57%|█████▋    | 234020/414113 [00:53<00:40, 4433.97it/s]\u001b[A\n",
      " 57%|█████▋    | 234464/414113 [00:53<00:40, 4422.84it/s]\u001b[A\n",
      " 57%|█████▋    | 234907/414113 [00:53<00:40, 4385.27it/s]\u001b[A\n",
      " 57%|█████▋    | 235346/414113 [00:53<00:41, 4356.07it/s]\u001b[A\n",
      " 57%|█████▋    | 235792/414113 [00:54<00:40, 4384.32it/s]\u001b[A\n",
      " 57%|█████▋    | 236234/414113 [00:54<00:40, 4392.43it/s]\u001b[A\n",
      " 57%|█████▋    | 236681/414113 [00:54<00:40, 4415.33it/s]\u001b[A\n",
      " 57%|█████▋    | 237125/414113 [00:54<00:40, 4420.94it/s]\u001b[A\n",
      " 57%|█████▋    | 237568/414113 [00:54<00:41, 4301.10it/s]\u001b[A\n",
      " 57%|█████▋    | 238019/414113 [00:54<00:40, 4359.57it/s]\u001b[A\n",
      " 58%|█████▊    | 238456/414113 [00:54<00:40, 4360.03it/s]\u001b[A\n",
      " 58%|█████▊    | 238903/414113 [00:54<00:39, 4392.12it/s]\u001b[A\n",
      " 58%|█████▊    | 239353/414113 [00:54<00:39, 4422.64it/s]\u001b[A\n",
      " 58%|█████▊    | 239796/414113 [00:54<00:39, 4367.45it/s]\u001b[A\n",
      " 58%|█████▊    | 240234/414113 [00:55<00:40, 4333.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 240668/414113 [00:55<00:40, 4328.68it/s]\u001b[A\n",
      " 58%|█████▊    | 241108/414113 [00:55<00:39, 4349.18it/s]\u001b[A\n",
      " 58%|█████▊    | 241544/414113 [00:55<00:39, 4339.07it/s]\u001b[A\n",
      " 58%|█████▊    | 241997/414113 [00:55<00:39, 4392.69it/s]\u001b[A\n",
      " 59%|█████▊    | 242437/414113 [00:55<00:39, 4356.97it/s]\u001b[A\n",
      " 59%|█████▊    | 242873/414113 [00:55<00:40, 4272.59it/s]\u001b[A\n",
      " 59%|█████▉    | 243323/414113 [00:55<00:39, 4336.46it/s]\u001b[A\n",
      " 59%|█████▉    | 243779/414113 [00:55<00:38, 4399.83it/s]\u001b[A\n",
      " 59%|█████▉    | 244220/414113 [00:55<00:39, 4318.63it/s]\u001b[A\n",
      " 59%|█████▉    | 244653/414113 [00:56<00:39, 4316.67it/s]\u001b[A\n",
      " 59%|█████▉    | 245108/414113 [00:56<00:38, 4381.76it/s]\u001b[A\n",
      " 59%|█████▉    | 245551/414113 [00:56<00:38, 4395.22it/s]\u001b[A\n",
      " 59%|█████▉    | 246000/414113 [00:56<00:38, 4422.81it/s]\u001b[A\n",
      " 60%|█████▉    | 246443/414113 [00:56<00:38, 4408.69it/s]\u001b[A\n",
      " 60%|█████▉    | 246888/414113 [00:56<00:37, 4419.54it/s]\u001b[A\n",
      " 60%|█████▉    | 247331/414113 [00:56<00:38, 4351.40it/s]\u001b[A\n",
      " 60%|█████▉    | 247782/414113 [00:56<00:37, 4396.06it/s]\u001b[A\n",
      " 60%|█████▉    | 248222/414113 [00:56<00:37, 4381.24it/s]\u001b[A\n",
      " 60%|██████    | 248661/414113 [00:56<00:37, 4357.25it/s]\u001b[A\n",
      " 60%|██████    | 249101/414113 [00:57<00:37, 4366.24it/s]\u001b[A\n",
      " 60%|██████    | 249538/414113 [00:57<00:37, 4333.56it/s]\u001b[A\n",
      " 60%|██████    | 249983/414113 [00:57<00:37, 4367.73it/s]\u001b[A\n",
      " 60%|██████    | 250430/414113 [00:57<00:37, 4395.18it/s]\u001b[A\n",
      " 61%|██████    | 250877/414113 [00:57<00:36, 4416.58it/s]\u001b[A\n",
      " 61%|██████    | 251325/414113 [00:57<00:36, 4432.62it/s]\u001b[A\n",
      " 61%|██████    | 251788/414113 [00:57<00:36, 4489.22it/s]\u001b[A\n",
      " 61%|██████    | 252252/414113 [00:57<00:35, 4531.70it/s]\u001b[A\n",
      " 61%|██████    | 252706/414113 [00:57<00:35, 4524.11it/s]\u001b[A\n",
      " 61%|██████    | 253159/414113 [00:57<00:35, 4488.23it/s]\u001b[A\n",
      " 61%|██████    | 253609/414113 [00:58<00:36, 4448.15it/s]\u001b[A\n",
      " 61%|██████▏   | 254071/414113 [00:58<00:35, 4498.35it/s]\u001b[A\n",
      " 61%|██████▏   | 254534/414113 [00:58<00:35, 4534.69it/s]\u001b[A\n",
      " 62%|██████▏   | 254998/414113 [00:58<00:34, 4565.56it/s]\u001b[A\n",
      " 62%|██████▏   | 255455/414113 [00:58<00:35, 4531.10it/s]\u001b[A\n",
      " 62%|██████▏   | 255920/414113 [00:58<00:34, 4565.75it/s]\u001b[A\n",
      " 62%|██████▏   | 256379/414113 [00:58<00:34, 4572.37it/s]\u001b[A\n",
      " 62%|██████▏   | 256839/414113 [00:58<00:34, 4578.85it/s]\u001b[A\n",
      " 62%|██████▏   | 257297/414113 [00:58<00:34, 4556.00it/s]\u001b[A\n",
      " 62%|██████▏   | 257753/414113 [00:58<00:34, 4496.04it/s]\u001b[A\n",
      " 62%|██████▏   | 258203/414113 [00:59<01:10, 2222.99it/s]\u001b[A\n",
      " 62%|██████▏   | 258659/414113 [00:59<00:59, 2626.04it/s]\u001b[A\n",
      " 63%|██████▎   | 259107/414113 [00:59<00:51, 2998.09it/s]\u001b[A\n",
      " 63%|██████▎   | 259563/414113 [00:59<00:46, 3340.33it/s]\u001b[A\n",
      " 63%|██████▎   | 260022/414113 [00:59<00:42, 3637.29it/s]\u001b[A\n",
      " 63%|██████▎   | 260468/414113 [00:59<00:39, 3850.26it/s]\u001b[A\n",
      " 63%|██████▎   | 260917/414113 [01:00<00:38, 4021.95it/s]\u001b[A\n",
      " 63%|██████▎   | 261378/414113 [01:00<00:36, 4181.29it/s]\u001b[A\n",
      " 63%|██████▎   | 261837/414113 [01:00<00:35, 4294.42it/s]\u001b[A\n",
      " 63%|██████▎   | 262287/414113 [01:00<00:35, 4315.24it/s]\u001b[A\n",
      " 63%|██████▎   | 262744/414113 [01:00<00:34, 4388.38it/s]\u001b[A\n",
      " 64%|██████▎   | 263193/414113 [01:00<00:34, 4402.18it/s]\u001b[A\n",
      " 64%|██████▎   | 263655/414113 [01:00<00:33, 4463.76it/s]\u001b[A\n",
      " 64%|██████▍   | 264107/414113 [01:00<00:33, 4463.36it/s]\u001b[A\n",
      " 64%|██████▍   | 264557/414113 [01:00<00:33, 4447.27it/s]\u001b[A\n",
      " 64%|██████▍   | 265005/414113 [01:00<00:33, 4389.00it/s]\u001b[A\n",
      " 64%|██████▍   | 265446/414113 [01:01<00:34, 4336.05it/s]\u001b[A\n",
      " 64%|██████▍   | 265882/414113 [01:01<00:34, 4323.14it/s]\u001b[A\n",
      " 64%|██████▍   | 266328/414113 [01:01<00:33, 4361.28it/s]\u001b[A\n",
      " 64%|██████▍   | 266777/414113 [01:01<00:33, 4397.09it/s]\u001b[A\n",
      " 65%|██████▍   | 267223/414113 [01:01<00:33, 4413.64it/s]\u001b[A\n",
      " 65%|██████▍   | 267682/414113 [01:01<00:32, 4463.65it/s]\u001b[A\n",
      " 65%|██████▍   | 268144/414113 [01:01<00:32, 4509.32it/s]\u001b[A\n",
      " 65%|██████▍   | 268596/414113 [01:01<00:32, 4494.54it/s]\u001b[A\n",
      " 65%|██████▍   | 269061/414113 [01:01<00:31, 4538.64it/s]\u001b[A\n",
      " 65%|██████▌   | 269516/414113 [01:01<00:32, 4501.62it/s]\u001b[A\n",
      " 65%|██████▌   | 269967/414113 [01:02<00:32, 4455.42it/s]\u001b[A\n",
      " 65%|██████▌   | 270421/414113 [01:02<00:32, 4478.57it/s]\u001b[A\n",
      " 65%|██████▌   | 270871/414113 [01:02<00:31, 4484.28it/s]\u001b[A\n",
      " 66%|██████▌   | 271337/414113 [01:02<00:31, 4532.96it/s]\u001b[A\n",
      " 66%|██████▌   | 271792/414113 [01:02<00:31, 4536.32it/s]\u001b[A\n",
      " 66%|██████▌   | 272246/414113 [01:02<00:31, 4516.15it/s]\u001b[A\n",
      " 66%|██████▌   | 272698/414113 [01:02<00:31, 4493.59it/s]\u001b[A\n",
      " 66%|██████▌   | 273148/414113 [01:02<00:31, 4492.63it/s]\u001b[A\n",
      " 66%|██████▌   | 273612/414113 [01:02<00:30, 4533.86it/s]\u001b[A\n",
      " 66%|██████▌   | 274066/414113 [01:02<00:31, 4446.50it/s]\u001b[A\n",
      " 66%|██████▋   | 274512/414113 [01:03<00:31, 4423.78it/s]\u001b[A\n",
      " 66%|██████▋   | 274956/414113 [01:03<00:31, 4425.10it/s]\u001b[A\n",
      " 67%|██████▋   | 275399/414113 [01:03<00:31, 4397.45it/s]\u001b[A\n",
      " 67%|██████▋   | 275848/414113 [01:03<00:31, 4423.56it/s]\u001b[A\n",
      " 67%|██████▋   | 276298/414113 [01:03<00:31, 4444.78it/s]\u001b[A\n",
      " 67%|██████▋   | 276743/414113 [01:03<00:30, 4443.50it/s]\u001b[A\n",
      " 67%|██████▋   | 277188/414113 [01:03<00:30, 4430.48it/s]\u001b[A\n",
      " 67%|██████▋   | 277633/414113 [01:03<00:30, 4435.09it/s]\u001b[A\n",
      " 67%|██████▋   | 278081/414113 [01:03<00:30, 4446.00it/s]\u001b[A\n",
      " 67%|██████▋   | 278526/414113 [01:03<00:30, 4409.53it/s]\u001b[A\n",
      " 67%|██████▋   | 278968/414113 [01:04<00:30, 4397.58it/s]\u001b[A\n",
      " 67%|██████▋   | 279413/414113 [01:04<00:30, 4412.16it/s]\u001b[A\n",
      " 68%|██████▊   | 279858/414113 [01:04<00:30, 4422.12it/s]\u001b[A\n",
      " 68%|██████▊   | 280324/414113 [01:04<00:29, 4489.26it/s]\u001b[A\n",
      " 68%|██████▊   | 280793/414113 [01:04<00:29, 4546.10it/s]\u001b[A\n",
      " 68%|██████▊   | 281248/414113 [01:04<00:29, 4529.59it/s]\u001b[A\n",
      " 68%|██████▊   | 281702/414113 [01:04<00:29, 4494.66it/s]\u001b[A\n",
      " 68%|██████▊   | 282166/414113 [01:04<00:29, 4535.10it/s]\u001b[A\n",
      " 68%|██████▊   | 282620/414113 [01:04<00:29, 4508.77it/s]\u001b[A\n",
      " 68%|██████▊   | 283072/414113 [01:04<00:29, 4443.56it/s]\u001b[A\n",
      " 68%|██████▊   | 283517/414113 [01:05<00:29, 4413.18it/s]\u001b[A\n",
      " 69%|██████▊   | 283971/414113 [01:05<00:29, 4448.48it/s]\u001b[A\n",
      " 69%|██████▊   | 284417/414113 [01:05<00:29, 4429.35it/s]\u001b[A\n",
      " 69%|██████▉   | 284879/414113 [01:05<00:28, 4483.63it/s]\u001b[A\n",
      " 69%|██████▉   | 285338/414113 [01:05<00:28, 4512.42it/s]\u001b[A\n",
      " 69%|██████▉   | 285790/414113 [01:05<00:28, 4488.56it/s]\u001b[A\n",
      " 69%|██████▉   | 286240/414113 [01:05<00:28, 4463.32it/s]\u001b[A\n",
      " 69%|██████▉   | 286687/414113 [01:05<00:28, 4463.73it/s]\u001b[A\n",
      " 69%|██████▉   | 287134/414113 [01:05<00:28, 4408.58it/s]\u001b[A\n",
      " 69%|██████▉   | 287580/414113 [01:06<00:28, 4421.17it/s]\u001b[A\n",
      " 70%|██████▉   | 288024/414113 [01:06<00:28, 4426.46it/s]\u001b[A\n",
      " 70%|██████▉   | 288467/414113 [01:06<00:28, 4409.67it/s]\u001b[A\n",
      " 70%|██████▉   | 288923/414113 [01:06<00:28, 4453.38it/s]\u001b[A\n",
      " 70%|██████▉   | 289369/414113 [01:06<00:28, 4420.76it/s]\u001b[A\n",
      " 70%|██████▉   | 289830/414113 [01:06<00:27, 4475.41it/s]\u001b[A\n",
      " 70%|███████   | 290295/414113 [01:06<00:27, 4524.04it/s]\u001b[A\n",
      " 70%|███████   | 290748/414113 [01:06<00:27, 4515.87it/s]\u001b[A\n",
      " 70%|███████   | 291200/414113 [01:06<00:27, 4490.55it/s]\u001b[A\n",
      " 70%|███████   | 291650/414113 [01:06<00:27, 4436.89it/s]\u001b[A\n",
      " 71%|███████   | 292094/414113 [01:07<00:27, 4431.22it/s]\u001b[A\n",
      " 71%|███████   | 292538/414113 [01:07<00:27, 4393.25it/s]\u001b[A\n",
      " 71%|███████   | 292978/414113 [01:07<00:27, 4363.80it/s]\u001b[A\n",
      " 71%|███████   | 293437/414113 [01:07<00:27, 4426.53it/s]\u001b[A\n",
      " 71%|███████   | 293881/414113 [01:07<00:27, 4398.33it/s]\u001b[A\n",
      " 71%|███████   | 294334/414113 [01:07<00:27, 4435.22it/s]\u001b[A\n",
      " 71%|███████   | 294778/414113 [01:07<00:26, 4432.19it/s]\u001b[A\n",
      " 71%|███████▏  | 295223/414113 [01:07<00:26, 4436.58it/s]\u001b[A\n",
      " 71%|███████▏  | 295682/414113 [01:07<00:26, 4478.41it/s]\u001b[A\n",
      " 72%|███████▏  | 296131/414113 [01:07<00:26, 4459.32it/s]\u001b[A\n",
      " 72%|███████▏  | 296578/414113 [01:08<00:26, 4425.99it/s]\u001b[A\n",
      " 72%|███████▏  | 297022/414113 [01:08<00:26, 4429.52it/s]\u001b[A\n",
      " 72%|███████▏  | 297466/414113 [01:08<00:26, 4425.37it/s]\u001b[A\n",
      " 72%|███████▏  | 297909/414113 [01:08<00:26, 4420.64it/s]\u001b[A\n",
      " 72%|███████▏  | 298352/414113 [01:08<00:26, 4410.51it/s]\u001b[A\n",
      " 72%|███████▏  | 298794/414113 [01:08<00:27, 4199.99it/s]\u001b[A\n",
      " 72%|███████▏  | 299244/414113 [01:08<00:26, 4285.40it/s]\u001b[A\n",
      " 72%|███████▏  | 299692/414113 [01:08<00:26, 4340.03it/s]\u001b[A\n",
      " 72%|███████▏  | 300128/414113 [01:08<00:26, 4328.44it/s]\u001b[A\n",
      " 73%|███████▎  | 300562/414113 [01:08<00:26, 4307.68it/s]\u001b[A\n",
      " 73%|███████▎  | 300994/414113 [01:09<00:26, 4280.83it/s]\u001b[A\n",
      " 73%|███████▎  | 301434/414113 [01:09<00:26, 4313.69it/s]\u001b[A\n",
      " 73%|███████▎  | 301884/414113 [01:09<00:25, 4365.37it/s]\u001b[A\n",
      " 73%|███████▎  | 302353/414113 [01:09<00:25, 4456.04it/s]\u001b[A\n",
      " 73%|███████▎  | 302801/414113 [01:09<00:24, 4461.16it/s]\u001b[A\n",
      " 73%|███████▎  | 303248/414113 [01:09<00:26, 4171.85it/s]\u001b[A\n",
      " 73%|███████▎  | 303688/414113 [01:09<00:26, 4236.00it/s]\u001b[A\n",
      " 73%|███████▎  | 304140/414113 [01:09<00:25, 4316.60it/s]\u001b[A\n",
      " 74%|███████▎  | 304575/414113 [01:09<00:25, 4325.30it/s]\u001b[A\n",
      " 74%|███████▎  | 305010/414113 [01:09<00:25, 4320.08it/s]\u001b[A\n",
      " 74%|███████▍  | 305444/414113 [01:10<00:25, 4290.25it/s]\u001b[A\n",
      " 74%|███████▍  | 305902/414113 [01:10<00:24, 4372.81it/s]\u001b[A\n",
      " 74%|███████▍  | 306341/414113 [01:10<00:24, 4373.65it/s]\u001b[A\n",
      " 74%|███████▍  | 306784/414113 [01:10<00:24, 4390.34it/s]\u001b[A\n",
      " 74%|███████▍  | 307232/414113 [01:10<00:24, 4416.78it/s]\u001b[A\n",
      " 74%|███████▍  | 307675/414113 [01:10<00:24, 4395.67it/s]\u001b[A\n",
      " 74%|███████▍  | 308115/414113 [01:10<00:24, 4376.05it/s]\u001b[A\n",
      " 75%|███████▍  | 308553/414113 [01:10<00:24, 4373.69it/s]\u001b[A\n",
      " 75%|███████▍  | 308991/414113 [01:10<00:24, 4370.12it/s]\u001b[A\n",
      " 75%|███████▍  | 309429/414113 [01:10<00:23, 4372.62it/s]\u001b[A\n",
      " 75%|███████▍  | 309871/414113 [01:11<00:23, 4384.47it/s]\u001b[A\n",
      " 75%|███████▍  | 310316/414113 [01:11<00:23, 4401.77it/s]\u001b[A\n",
      " 75%|███████▌  | 310759/414113 [01:11<00:23, 4409.43it/s]\u001b[A\n",
      " 75%|███████▌  | 311202/414113 [01:11<00:23, 4413.60it/s]\u001b[A\n",
      " 75%|███████▌  | 311663/414113 [01:11<00:22, 4469.15it/s]\u001b[A\n",
      " 75%|███████▌  | 312113/414113 [01:11<00:22, 4477.00it/s]\u001b[A\n",
      " 75%|███████▌  | 312567/414113 [01:11<00:22, 4493.65it/s]\u001b[A\n",
      " 76%|███████▌  | 313022/414113 [01:11<00:22, 4509.75it/s]\u001b[A\n",
      " 76%|███████▌  | 313474/414113 [01:11<00:22, 4512.30it/s]\u001b[A\n",
      " 76%|███████▌  | 313926/414113 [01:11<00:22, 4473.00it/s]\u001b[A\n",
      " 76%|███████▌  | 314374/414113 [01:12<00:22, 4456.39it/s]\u001b[A\n",
      " 76%|███████▌  | 314820/414113 [01:12<00:22, 4447.65it/s]\u001b[A\n",
      " 76%|███████▌  | 315265/414113 [01:12<00:22, 4431.97it/s]\u001b[A\n",
      " 76%|███████▌  | 315728/414113 [01:12<00:21, 4488.71it/s]\u001b[A\n",
      " 76%|███████▋  | 316183/414113 [01:12<00:21, 4506.51it/s]\u001b[A\n",
      " 76%|███████▋  | 316634/414113 [01:12<00:21, 4451.45it/s]\u001b[A\n",
      " 77%|███████▋  | 317081/414113 [01:12<00:21, 4455.03it/s]\u001b[A\n",
      " 77%|███████▋  | 317535/414113 [01:12<00:21, 4477.25it/s]\u001b[A\n",
      " 77%|███████▋  | 317983/414113 [01:12<00:21, 4428.37it/s]\u001b[A\n",
      " 77%|███████▋  | 318435/414113 [01:13<00:21, 4454.42it/s]\u001b[A\n",
      " 77%|███████▋  | 318881/414113 [01:13<00:21, 4454.50it/s]\u001b[A\n",
      " 77%|███████▋  | 319327/414113 [01:13<00:21, 4445.39it/s]\u001b[A\n",
      " 77%|███████▋  | 319772/414113 [01:13<00:21, 4445.93it/s]\u001b[A\n",
      " 77%|███████▋  | 320241/414113 [01:13<00:20, 4513.97it/s]\u001b[A\n",
      " 77%|███████▋  | 320701/414113 [01:13<00:20, 4538.04it/s]\u001b[A\n",
      " 78%|███████▊  | 321159/414113 [01:13<00:20, 4547.84it/s]\u001b[A\n",
      " 78%|███████▊  | 321619/414113 [01:13<00:20, 4563.03it/s]\u001b[A\n",
      " 78%|███████▊  | 322076/414113 [01:13<00:20, 4544.73it/s]\u001b[A\n",
      " 78%|███████▊  | 322531/414113 [01:13<00:20, 4522.61it/s]\u001b[A\n",
      " 78%|███████▊  | 322984/414113 [01:14<00:20, 4521.84it/s]\u001b[A\n",
      " 78%|███████▊  | 323437/414113 [01:14<00:20, 4490.71it/s]\u001b[A\n",
      " 78%|███████▊  | 323887/414113 [01:14<00:20, 4479.32it/s]\u001b[A\n",
      " 78%|███████▊  | 324336/414113 [01:14<00:20, 4453.43it/s]\u001b[A\n",
      " 78%|███████▊  | 324806/414113 [01:14<00:19, 4521.28it/s]\u001b[A\n",
      " 79%|███████▊  | 325263/414113 [01:14<00:19, 4535.22it/s]\u001b[A\n",
      " 79%|███████▊  | 325717/414113 [01:14<00:19, 4502.66it/s]\u001b[A\n",
      " 79%|███████▉  | 326168/414113 [01:14<00:20, 4365.00it/s]\u001b[A\n",
      " 79%|███████▉  | 326635/414113 [01:14<00:19, 4449.89it/s]\u001b[A\n",
      " 79%|███████▉  | 327082/414113 [01:14<00:19, 4433.63it/s]\u001b[A\n",
      " 79%|███████▉  | 327532/414113 [01:15<00:19, 4452.76it/s]\u001b[A\n",
      " 79%|███████▉  | 327978/414113 [01:15<00:19, 4438.51it/s]\u001b[A\n",
      " 79%|███████▉  | 328424/414113 [01:15<00:19, 4444.41it/s]\u001b[A\n",
      " 79%|███████▉  | 328869/414113 [01:15<00:19, 4404.38it/s]\u001b[A\n",
      " 80%|███████▉  | 329310/414113 [01:15<00:19, 4377.70it/s]\u001b[A\n",
      " 80%|███████▉  | 329749/414113 [01:15<00:19, 4374.23it/s]\u001b[A\n",
      " 80%|███████▉  | 330187/414113 [01:15<00:19, 4362.43it/s]\u001b[A\n",
      " 80%|███████▉  | 330624/414113 [01:15<00:19, 4352.93it/s]\u001b[A\n",
      " 80%|███████▉  | 331060/414113 [01:15<00:19, 4333.05it/s]\u001b[A\n",
      " 80%|████████  | 331494/414113 [01:15<00:19, 4290.17it/s]\u001b[A\n",
      " 80%|████████  | 331924/414113 [01:16<00:19, 4280.08it/s]\u001b[A\n",
      " 80%|████████  | 332353/414113 [01:16<00:19, 4270.80it/s]\u001b[A\n",
      " 80%|████████  | 332808/414113 [01:16<00:18, 4349.80it/s]\u001b[A\n",
      " 80%|████████  | 333244/414113 [01:16<00:18, 4289.70it/s]\u001b[A\n",
      " 81%|████████  | 333680/414113 [01:16<00:18, 4309.28it/s]\u001b[A\n",
      " 81%|████████  | 334113/414113 [01:16<00:18, 4314.16it/s]\u001b[A\n",
      " 81%|████████  | 334545/414113 [01:16<00:18, 4293.55it/s]\u001b[A\n",
      " 81%|████████  | 334984/414113 [01:16<00:18, 4319.71it/s]\u001b[A\n",
      " 81%|████████  | 335428/414113 [01:16<00:18, 4354.13it/s]\u001b[A\n",
      " 81%|████████  | 335867/414113 [01:16<00:17, 4363.09it/s]\u001b[A\n",
      " 81%|████████  | 336304/414113 [01:17<00:17, 4327.05it/s]\u001b[A\n",
      " 81%|████████▏ | 336740/414113 [01:17<00:17, 4336.56it/s]\u001b[A\n",
      " 81%|████████▏ | 337174/414113 [01:17<00:18, 4270.12it/s]\u001b[A\n",
      " 82%|████████▏ | 337614/414113 [01:17<00:17, 4307.19it/s]\u001b[A\n",
      " 82%|████████▏ | 338047/414113 [01:17<00:17, 4311.25it/s]\u001b[A\n",
      " 82%|████████▏ | 338479/414113 [01:17<00:17, 4277.23it/s]\u001b[A\n",
      " 82%|████████▏ | 338927/414113 [01:17<00:17, 4333.58it/s]\u001b[A\n",
      " 82%|████████▏ | 339361/414113 [01:17<00:17, 4324.67it/s]\u001b[A\n",
      " 82%|████████▏ | 339813/414113 [01:17<00:16, 4380.57it/s]\u001b[A\n",
      " 82%|████████▏ | 340252/414113 [01:17<00:16, 4358.84it/s]\u001b[A\n",
      " 82%|████████▏ | 340689/414113 [01:18<00:16, 4339.20it/s]\u001b[A\n",
      " 82%|████████▏ | 341124/414113 [01:18<00:16, 4333.86it/s]\u001b[A\n",
      " 82%|████████▏ | 341564/414113 [01:18<00:16, 4352.70it/s]\u001b[A\n",
      " 83%|████████▎ | 342019/414113 [01:18<00:16, 4408.77it/s]\u001b[A\n",
      " 83%|████████▎ | 342468/414113 [01:18<00:16, 4432.52it/s]\u001b[A\n",
      " 83%|████████▎ | 342922/414113 [01:18<00:15, 4460.78it/s]\u001b[A\n",
      " 83%|████████▎ | 343372/414113 [01:18<00:15, 4472.45it/s]\u001b[A\n",
      " 83%|████████▎ | 343820/414113 [01:18<00:15, 4472.85it/s]\u001b[A\n",
      " 83%|████████▎ | 344268/414113 [01:18<00:15, 4449.85it/s]\u001b[A\n",
      " 83%|████████▎ | 344714/414113 [01:18<00:15, 4416.57it/s]\u001b[A\n",
      " 83%|████████▎ | 345156/414113 [01:19<00:15, 4364.96it/s]\u001b[A\n",
      " 83%|████████▎ | 345604/414113 [01:19<00:15, 4398.61it/s]\u001b[A\n",
      " 84%|████████▎ | 346045/414113 [01:19<00:15, 4385.40it/s]\u001b[A\n",
      " 84%|████████▎ | 346484/414113 [01:19<00:15, 4375.50it/s]\u001b[A\n",
      " 84%|████████▍ | 346922/414113 [01:19<00:15, 4343.54it/s]\u001b[A\n",
      " 84%|████████▍ | 347379/414113 [01:19<00:15, 4407.31it/s]\u001b[A\n",
      " 84%|████████▍ | 347822/414113 [01:19<00:15, 4411.97it/s]\u001b[A\n",
      " 84%|████████▍ | 348264/414113 [01:19<00:14, 4407.56it/s]\u001b[A\n",
      " 84%|████████▍ | 348705/414113 [01:19<00:14, 4392.12it/s]\u001b[A\n",
      " 84%|████████▍ | 349145/414113 [01:20<00:15, 4166.49it/s]\u001b[A\n",
      " 84%|████████▍ | 349591/414113 [01:20<00:15, 4249.68it/s]\u001b[A\n",
      " 85%|████████▍ | 350031/414113 [01:20<00:14, 4292.15it/s]\u001b[A\n",
      " 85%|████████▍ | 350470/414113 [01:20<00:14, 4319.21it/s]\u001b[A\n",
      " 85%|████████▍ | 350919/414113 [01:20<00:14, 4365.97it/s]\u001b[A\n",
      " 85%|████████▍ | 351381/414113 [01:20<00:14, 4437.71it/s]\u001b[A\n",
      " 85%|████████▍ | 351831/414113 [01:20<00:13, 4454.72it/s]\u001b[A\n",
      " 85%|████████▌ | 352286/414113 [01:20<00:13, 4480.93it/s]\u001b[A\n",
      " 85%|████████▌ | 352735/414113 [01:20<00:13, 4414.84it/s]\u001b[A\n",
      " 85%|████████▌ | 353178/414113 [01:20<00:13, 4414.19it/s]\u001b[A\n",
      " 85%|████████▌ | 353620/414113 [01:21<00:13, 4364.91it/s]\u001b[A\n",
      " 85%|████████▌ | 354057/414113 [01:21<00:13, 4366.23it/s]\u001b[A\n",
      " 86%|████████▌ | 354499/414113 [01:21<00:13, 4379.66it/s]\u001b[A\n",
      " 86%|████████▌ | 354948/414113 [01:21<00:13, 4410.38it/s]\u001b[A\n",
      " 86%|████████▌ | 355401/414113 [01:21<00:13, 4440.50it/s]\u001b[A\n",
      " 86%|████████▌ | 355846/414113 [01:21<00:13, 4421.23it/s]\u001b[A\n",
      " 86%|████████▌ | 356307/414113 [01:21<00:12, 4474.51it/s]\u001b[A\n",
      " 86%|████████▌ | 356755/414113 [01:21<00:12, 4452.63it/s]\u001b[A\n",
      " 86%|████████▋ | 357201/414113 [01:21<00:12, 4435.45it/s]\u001b[A\n",
      " 86%|████████▋ | 357645/414113 [01:21<00:12, 4430.75it/s]\u001b[A\n",
      " 86%|████████▋ | 358089/414113 [01:22<00:12, 4344.71it/s]\u001b[A\n",
      " 87%|████████▋ | 358527/414113 [01:22<00:12, 4354.39it/s]\u001b[A\n",
      " 87%|████████▋ | 358970/414113 [01:22<00:12, 4375.06it/s]\u001b[A\n",
      " 87%|████████▋ | 359408/414113 [01:22<00:12, 4360.07it/s]\u001b[A\n",
      " 87%|████████▋ | 359845/414113 [01:22<00:12, 4353.93it/s]\u001b[A\n",
      " 87%|████████▋ | 360294/414113 [01:22<00:12, 4393.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 360737/414113 [01:22<00:12, 4401.58it/s]\u001b[A\n",
      " 87%|████████▋ | 361187/414113 [01:22<00:11, 4428.09it/s]\u001b[A\n",
      " 87%|████████▋ | 361632/414113 [01:22<00:11, 4432.33it/s]\u001b[A\n",
      " 87%|████████▋ | 362076/414113 [01:22<00:11, 4417.71it/s]\u001b[A\n",
      " 88%|████████▊ | 362521/414113 [01:23<00:11, 4425.61it/s]\u001b[A\n",
      " 88%|████████▊ | 362964/414113 [01:23<00:11, 4375.86it/s]\u001b[A\n",
      " 88%|████████▊ | 363402/414113 [01:23<00:11, 4349.64it/s]\u001b[A\n",
      " 88%|████████▊ | 363838/414113 [01:23<00:11, 4336.55it/s]\u001b[A\n",
      " 88%|████████▊ | 364290/414113 [01:23<00:11, 4387.46it/s]\u001b[A\n",
      " 88%|████████▊ | 364739/414113 [01:23<00:11, 4415.98it/s]\u001b[A\n",
      " 88%|████████▊ | 365181/414113 [01:23<00:11, 4407.61it/s]\u001b[A\n",
      " 88%|████████▊ | 365630/414113 [01:23<00:10, 4431.45it/s]\u001b[A\n",
      " 88%|████████▊ | 366082/414113 [01:23<00:10, 4456.40it/s]\u001b[A\n",
      " 89%|████████▊ | 366528/414113 [01:23<00:10, 4400.90it/s]\u001b[A\n",
      " 89%|████████▊ | 366969/414113 [01:24<00:10, 4369.63it/s]\u001b[A\n",
      " 89%|████████▊ | 367407/414113 [01:24<00:10, 4355.80it/s]\u001b[A\n",
      " 89%|████████▉ | 367859/414113 [01:24<00:10, 4402.95it/s]\u001b[A\n",
      " 89%|████████▉ | 368314/414113 [01:24<00:10, 4443.83it/s]\u001b[A\n",
      " 89%|████████▉ | 368761/414113 [01:24<00:10, 4450.77it/s]\u001b[A\n",
      " 89%|████████▉ | 369213/414113 [01:24<00:10, 4469.06it/s]\u001b[A\n",
      " 89%|████████▉ | 369661/414113 [01:24<00:10, 4418.93it/s]\u001b[A\n",
      " 89%|████████▉ | 370111/414113 [01:24<00:09, 4441.25it/s]\u001b[A\n",
      " 89%|████████▉ | 370556/414113 [01:24<00:09, 4368.93it/s]\u001b[A\n",
      " 90%|████████▉ | 370997/414113 [01:24<00:09, 4378.75it/s]\u001b[A\n",
      " 90%|████████▉ | 371436/414113 [01:25<00:09, 4355.38it/s]\u001b[A\n",
      " 90%|████████▉ | 371872/414113 [01:25<00:09, 4351.55it/s]\u001b[A\n",
      " 90%|████████▉ | 372313/414113 [01:25<00:09, 4367.94it/s]\u001b[A\n",
      " 90%|█████████ | 372752/414113 [01:25<00:09, 4374.11it/s]\u001b[A\n",
      " 90%|█████████ | 373190/414113 [01:25<00:09, 4366.41it/s]\u001b[A\n",
      " 90%|█████████ | 373640/414113 [01:25<00:09, 4404.26it/s]\u001b[A\n",
      " 90%|█████████ | 374096/414113 [01:25<00:08, 4448.40it/s]\u001b[A\n",
      " 90%|█████████ | 374546/414113 [01:25<00:08, 4461.10it/s]\u001b[A\n",
      " 91%|█████████ | 374993/414113 [01:25<00:08, 4415.66it/s]\u001b[A\n",
      " 91%|█████████ | 375435/414113 [01:25<00:08, 4368.96it/s]\u001b[A\n",
      " 91%|█████████ | 375873/414113 [01:26<00:09, 4112.55it/s]\u001b[A\n",
      " 91%|█████████ | 376288/414113 [01:26<00:09, 4106.79it/s]\u001b[A\n",
      " 91%|█████████ | 376720/414113 [01:26<00:08, 4164.99it/s]\u001b[A\n",
      " 91%|█████████ | 377141/414113 [01:26<00:08, 4175.79it/s]\u001b[A\n",
      " 91%|█████████ | 377566/414113 [01:26<00:08, 4196.72it/s]\u001b[A\n",
      " 91%|█████████▏| 377996/414113 [01:26<00:08, 4224.64it/s]\u001b[A\n",
      " 91%|█████████▏| 378431/414113 [01:26<00:08, 4259.93it/s]\u001b[A\n",
      " 91%|█████████▏| 378883/414113 [01:26<00:08, 4333.91it/s]\u001b[A\n",
      " 92%|█████████▏| 379325/414113 [01:26<00:07, 4359.15it/s]\u001b[A\n",
      " 92%|█████████▏| 379762/414113 [01:27<00:07, 4323.74it/s]\u001b[A\n",
      " 92%|█████████▏| 380195/414113 [01:27<00:07, 4300.04it/s]\u001b[A\n",
      " 92%|█████████▏| 380627/414113 [01:27<00:07, 4302.32it/s]\u001b[A\n",
      " 92%|█████████▏| 381059/414113 [01:27<00:07, 4305.12it/s]\u001b[A\n",
      " 92%|█████████▏| 381510/414113 [01:27<00:07, 4363.66it/s]\u001b[A\n",
      " 92%|█████████▏| 381961/414113 [01:27<00:07, 4405.19it/s]\u001b[A\n",
      " 92%|█████████▏| 382406/414113 [01:27<00:07, 4417.27it/s]\u001b[A\n",
      " 92%|█████████▏| 382854/414113 [01:27<00:07, 4435.78it/s]\u001b[A\n",
      " 93%|█████████▎| 383298/414113 [01:27<00:06, 4429.67it/s]\u001b[A\n",
      " 93%|█████████▎| 383753/414113 [01:27<00:06, 4464.74it/s]\u001b[A\n",
      " 93%|█████████▎| 384200/414113 [01:28<00:06, 4403.48it/s]\u001b[A\n",
      " 93%|█████████▎| 384641/414113 [01:28<00:06, 4375.31it/s]\u001b[A\n",
      " 93%|█████████▎| 385080/414113 [01:28<00:06, 4378.73it/s]\u001b[A\n",
      " 93%|█████████▎| 385519/414113 [01:28<00:06, 4365.45it/s]\u001b[A\n",
      " 93%|█████████▎| 385956/414113 [01:28<00:06, 4340.61it/s]\u001b[A\n",
      " 93%|█████████▎| 386401/414113 [01:28<00:06, 4369.64it/s]\u001b[A\n",
      " 93%|█████████▎| 386845/414113 [01:28<00:06, 4389.29it/s]\u001b[A\n",
      " 94%|█████████▎| 387288/414113 [01:28<00:06, 4399.72it/s]\u001b[A\n",
      " 94%|█████████▎| 387729/414113 [01:28<00:06, 4394.60it/s]\u001b[A\n",
      " 94%|█████████▎| 388169/414113 [01:28<00:05, 4384.21it/s]\u001b[A\n",
      " 94%|█████████▍| 388608/414113 [01:29<00:05, 4348.02it/s]\u001b[A\n",
      " 94%|█████████▍| 389045/414113 [01:29<00:05, 4352.09it/s]\u001b[A\n",
      " 94%|█████████▍| 389481/414113 [01:29<00:05, 4319.25it/s]\u001b[A\n",
      " 94%|█████████▍| 389925/414113 [01:29<00:05, 4354.62it/s]\u001b[A\n",
      " 94%|█████████▍| 390379/414113 [01:29<00:05, 4406.12it/s]\u001b[A\n",
      " 94%|█████████▍| 390820/414113 [01:29<00:05, 4399.07it/s]\u001b[A\n",
      " 94%|█████████▍| 391261/414113 [01:29<00:05, 4396.68it/s]\u001b[A\n",
      " 95%|█████████▍| 391713/414113 [01:29<00:05, 4432.46it/s]\u001b[A\n",
      " 95%|█████████▍| 392169/414113 [01:29<00:04, 4468.90it/s]\u001b[A\n",
      " 95%|█████████▍| 392617/414113 [01:29<00:04, 4445.92it/s]\u001b[A\n",
      " 95%|█████████▍| 393062/414113 [01:30<00:04, 4419.50it/s]\u001b[A\n",
      " 95%|█████████▌| 393505/414113 [01:30<00:04, 4218.42it/s]\u001b[A\n",
      " 95%|█████████▌| 393944/414113 [01:30<00:04, 4265.94it/s]\u001b[A\n",
      " 95%|█████████▌| 394373/414113 [01:30<00:04, 4243.63it/s]\u001b[A\n",
      " 95%|█████████▌| 394803/414113 [01:30<00:04, 4257.90it/s]\u001b[A\n",
      " 95%|█████████▌| 395232/414113 [01:30<00:04, 4265.25it/s]\u001b[A\n",
      " 96%|█████████▌| 395677/414113 [01:30<00:04, 4319.02it/s]\u001b[A\n",
      " 96%|█████████▌| 396121/414113 [01:30<00:04, 4353.39it/s]\u001b[A\n",
      " 96%|█████████▌| 396557/414113 [01:30<00:04, 4325.05it/s]\u001b[A\n",
      " 96%|█████████▌| 396993/414113 [01:30<00:03, 4335.18it/s]\u001b[A\n",
      " 96%|█████████▌| 397427/414113 [01:31<00:03, 4310.12it/s]\u001b[A\n",
      " 96%|█████████▌| 397859/414113 [01:31<00:03, 4262.55it/s]\u001b[A\n",
      " 96%|█████████▌| 398311/414113 [01:31<00:03, 4336.64it/s]\u001b[A\n",
      " 96%|█████████▋| 398766/414113 [01:31<00:03, 4396.85it/s]\u001b[A\n",
      " 96%|█████████▋| 399212/414113 [01:31<00:03, 4414.57it/s]\u001b[A\n",
      " 97%|█████████▋| 399659/414113 [01:31<00:03, 4428.61it/s]\u001b[A\n",
      " 97%|█████████▋| 400106/414113 [01:31<00:03, 4440.51it/s]\u001b[A\n",
      " 97%|█████████▋| 400551/414113 [01:31<00:03, 4437.23it/s]\u001b[A\n",
      " 97%|█████████▋| 401014/414113 [01:31<00:02, 4492.42it/s]\u001b[A\n",
      " 97%|█████████▋| 401464/414113 [01:31<00:02, 4442.50it/s]\u001b[A\n",
      " 97%|█████████▋| 401912/414113 [01:32<00:02, 4451.85it/s]\u001b[A\n",
      " 97%|█████████▋| 402358/414113 [01:32<00:02, 4424.56it/s]\u001b[A\n",
      " 97%|█████████▋| 402803/414113 [01:32<00:02, 4431.62it/s]\u001b[A\n",
      " 97%|█████████▋| 403247/414113 [01:32<00:02, 4413.35it/s]\u001b[A\n",
      " 97%|█████████▋| 403699/414113 [01:32<00:02, 4443.77it/s]\u001b[A\n",
      " 98%|█████████▊| 404144/414113 [01:32<00:02, 4414.17it/s]\u001b[A\n",
      " 98%|█████████▊| 404599/414113 [01:32<00:02, 4452.40it/s]\u001b[A\n",
      " 98%|█████████▊| 405045/414113 [01:32<00:02, 4454.00it/s]\u001b[A\n",
      " 98%|█████████▊| 405492/414113 [01:32<00:01, 4456.17it/s]\u001b[A\n",
      " 98%|█████████▊| 405938/414113 [01:32<00:01, 4392.38it/s]\u001b[A\n",
      " 98%|█████████▊| 406378/414113 [01:33<00:01, 4379.36it/s]\u001b[A\n",
      " 98%|█████████▊| 406817/414113 [01:33<00:01, 4362.54it/s]\u001b[A\n",
      " 98%|█████████▊| 407274/414113 [01:33<00:01, 4422.60it/s]\u001b[A\n",
      " 98%|█████████▊| 407719/414113 [01:33<00:01, 4430.29it/s]\u001b[A\n",
      " 99%|█████████▊| 408163/414113 [01:33<00:01, 4400.72it/s]\u001b[A\n",
      " 99%|█████████▊| 408618/414113 [01:33<00:01, 4442.31it/s]\u001b[A\n",
      " 99%|█████████▉| 409064/414113 [01:33<00:01, 4446.17it/s]\u001b[A\n",
      " 99%|█████████▉| 409509/414113 [01:33<00:01, 4445.08it/s]\u001b[A\n",
      " 99%|█████████▉| 409954/414113 [01:33<00:00, 4430.90it/s]\u001b[A\n",
      " 99%|█████████▉| 410406/414113 [01:33<00:00, 4455.03it/s]\u001b[A\n",
      " 99%|█████████▉| 410852/414113 [01:34<00:00, 4425.69it/s]\u001b[A\n",
      " 99%|█████████▉| 411299/414113 [01:34<00:00, 4436.01it/s]\u001b[A\n",
      " 99%|█████████▉| 411743/414113 [01:34<00:00, 4405.63it/s]\u001b[A\n",
      "100%|█████████▉| 412208/414113 [01:34<00:00, 4475.49it/s]\u001b[A\n",
      "100%|█████████▉| 412656/414113 [01:34<00:00, 4474.03it/s]\u001b[A\n",
      "100%|█████████▉| 413119/414113 [01:34<00:00, 4518.39it/s]\u001b[A\n",
      "100%|█████████▉| 413582/414113 [01:34<00:00, 4551.13it/s]\u001b[A\n",
      "100%|█████████▉| 414038/414113 [01:34<00:00, 4398.56it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:34<00:00, 4367.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/12942], Loss: 3.9947, Perplexity: 54.3077\n",
      "Epoch [1/3], Step [200/12942], Loss: 3.2723, Perplexity: 26.3710\n",
      "Epoch [1/3], Step [300/12942], Loss: 3.2397, Perplexity: 25.5269\n",
      "Epoch [1/3], Step [400/12942], Loss: 3.2515, Perplexity: 25.8280\n",
      "Epoch [1/3], Step [500/12942], Loss: 3.5386, Perplexity: 34.4182\n",
      "Epoch [1/3], Step [600/12942], Loss: 3.1960, Perplexity: 24.4357\n",
      "Epoch [1/3], Step [700/12942], Loss: 3.2307, Perplexity: 25.2961\n",
      "Epoch [1/3], Step [800/12942], Loss: 3.0636, Perplexity: 21.40375\n",
      "Epoch [1/3], Step [900/12942], Loss: 3.5093, Perplexity: 33.42322\n",
      "Epoch [1/3], Step [1000/12942], Loss: 3.1853, Perplexity: 24.1752\n",
      "Epoch [1/3], Step [1100/12942], Loss: 3.1602, Perplexity: 23.5758\n",
      "Epoch [1/3], Step [1200/12942], Loss: 3.2189, Perplexity: 25.0006\n",
      "Epoch [1/3], Step [1300/12942], Loss: 3.1351, Perplexity: 22.9920\n",
      "Epoch [1/3], Step [1400/12942], Loss: 2.5078, Perplexity: 12.27796\n",
      "Epoch [1/3], Step [1500/12942], Loss: 2.9159, Perplexity: 18.4648\n",
      "Epoch [1/3], Step [1600/12942], Loss: 3.1157, Perplexity: 22.5485\n",
      "Epoch [1/3], Step [1700/12942], Loss: 2.7427, Perplexity: 15.5285\n",
      "Epoch [1/3], Step [1800/12942], Loss: 3.1226, Perplexity: 22.7049\n",
      "Epoch [1/3], Step [1900/12942], Loss: 2.6713, Perplexity: 14.4588\n",
      "Epoch [1/3], Step [2000/12942], Loss: 2.4106, Perplexity: 11.1405\n",
      "Epoch [1/3], Step [2100/12942], Loss: 2.4611, Perplexity: 11.7171\n",
      "Epoch [1/3], Step [2200/12942], Loss: 3.3645, Perplexity: 28.9196\n",
      "Epoch [1/3], Step [2300/12942], Loss: 2.3560, Perplexity: 10.5487\n",
      "Epoch [1/3], Step [2400/12942], Loss: 2.6378, Perplexity: 13.9817\n",
      "Epoch [1/3], Step [2500/12942], Loss: 2.8473, Perplexity: 17.2416\n",
      "Epoch [1/3], Step [2600/12942], Loss: 2.3061, Perplexity: 10.0352\n",
      "Epoch [1/3], Step [2700/12942], Loss: 2.7437, Perplexity: 15.5444\n",
      "Epoch [1/3], Step [2800/12942], Loss: 2.7522, Perplexity: 15.6771\n",
      "Epoch [1/3], Step [2900/12942], Loss: 2.2803, Perplexity: 9.78003\n",
      "Epoch [1/3], Step [3000/12942], Loss: 2.3688, Perplexity: 10.6844\n",
      "Epoch [1/3], Step [3100/12942], Loss: 2.8506, Perplexity: 17.2986\n",
      "Epoch [1/3], Step [3200/12942], Loss: 2.4240, Perplexity: 11.2909\n",
      "Epoch [1/3], Step [3300/12942], Loss: 2.5024, Perplexity: 12.2119\n",
      "Epoch [1/3], Step [3400/12942], Loss: 3.0550, Perplexity: 21.2206\n",
      "Epoch [1/3], Step [3500/12942], Loss: 2.4186, Perplexity: 11.2306\n",
      "Epoch [1/3], Step [3600/12942], Loss: 2.1936, Perplexity: 8.96707\n",
      "Epoch [1/3], Step [3700/12942], Loss: 2.3709, Perplexity: 10.7067\n",
      "Epoch [1/3], Step [3800/12942], Loss: 2.4525, Perplexity: 11.6171\n",
      "Epoch [1/3], Step [3900/12942], Loss: 2.5466, Perplexity: 12.7637\n",
      "Epoch [1/3], Step [4000/12942], Loss: 2.4652, Perplexity: 11.7656\n",
      "Epoch [1/3], Step [4100/12942], Loss: 2.5011, Perplexity: 12.1959\n",
      "Epoch [1/3], Step [4200/12942], Loss: 2.0418, Perplexity: 7.70437\n",
      "Epoch [1/3], Step [4300/12942], Loss: 2.5712, Perplexity: 13.0814\n",
      "Epoch [1/3], Step [4400/12942], Loss: 2.4680, Perplexity: 11.7984\n",
      "Epoch [1/3], Step [4500/12942], Loss: 2.4130, Perplexity: 11.1669\n",
      "Epoch [1/3], Step [4600/12942], Loss: 2.2588, Perplexity: 9.57163\n",
      "Epoch [1/3], Step [4700/12942], Loss: 2.5584, Perplexity: 12.9155\n",
      "Epoch [1/3], Step [4800/12942], Loss: 2.2631, Perplexity: 9.61259\n",
      "Epoch [1/3], Step [4900/12942], Loss: 2.3167, Perplexity: 10.1423\n",
      "Epoch [1/3], Step [5000/12942], Loss: 2.3997, Perplexity: 11.0201\n",
      "Epoch [1/3], Step [5100/12942], Loss: 2.5332, Perplexity: 12.5939\n",
      "Epoch [1/3], Step [5200/12942], Loss: 2.4027, Perplexity: 11.0532\n",
      "Epoch [1/3], Step [5300/12942], Loss: 2.2651, Perplexity: 9.63256\n",
      "Epoch [1/3], Step [5400/12942], Loss: 2.1427, Perplexity: 8.52252\n",
      "Epoch [1/3], Step [5500/12942], Loss: 2.5258, Perplexity: 12.5007\n",
      "Epoch [1/3], Step [5600/12942], Loss: 2.7677, Perplexity: 15.9226\n",
      "Epoch [1/3], Step [5700/12942], Loss: 2.4184, Perplexity: 11.2276\n",
      "Epoch [1/3], Step [5800/12942], Loss: 2.1490, Perplexity: 8.57645\n",
      "Epoch [1/3], Step [5900/12942], Loss: 2.5973, Perplexity: 13.4278\n",
      "Epoch [1/3], Step [6000/12942], Loss: 2.5984, Perplexity: 13.4428\n",
      "Epoch [1/3], Step [6100/12942], Loss: 2.1859, Perplexity: 8.89897\n",
      "Epoch [1/3], Step [6200/12942], Loss: 2.3499, Perplexity: 10.4845\n",
      "Epoch [1/3], Step [6300/12942], Loss: 2.5134, Perplexity: 12.3471\n",
      "Epoch [1/3], Step [6400/12942], Loss: 2.0562, Perplexity: 7.81628\n",
      "Epoch [1/3], Step [6500/12942], Loss: 2.5657, Perplexity: 13.0096\n",
      "Epoch [1/3], Step [6600/12942], Loss: 2.2678, Perplexity: 9.65838\n",
      "Epoch [1/3], Step [6700/12942], Loss: 2.0325, Perplexity: 7.63352\n",
      "Epoch [1/3], Step [6800/12942], Loss: 2.2072, Perplexity: 9.09067\n",
      "Epoch [1/3], Step [6900/12942], Loss: 2.2539, Perplexity: 9.52489\n",
      "Epoch [1/3], Step [7000/12942], Loss: 2.0562, Perplexity: 7.81650\n",
      "Epoch [1/3], Step [7100/12942], Loss: 2.0706, Perplexity: 7.92950\n",
      "Epoch [1/3], Step [7200/12942], Loss: 2.2926, Perplexity: 9.90084\n",
      "Epoch [1/3], Step [7300/12942], Loss: 2.5569, Perplexity: 12.8954\n",
      "Epoch [1/3], Step [7400/12942], Loss: 2.1978, Perplexity: 9.00489\n",
      "Epoch [1/3], Step [7500/12942], Loss: 2.1600, Perplexity: 8.67136\n",
      "Epoch [1/3], Step [7600/12942], Loss: 2.1180, Perplexity: 8.31447\n",
      "Epoch [1/3], Step [7700/12942], Loss: 2.1781, Perplexity: 8.82970\n",
      "Epoch [1/3], Step [7800/12942], Loss: 3.2545, Perplexity: 25.9065\n",
      "Epoch [1/3], Step [7900/12942], Loss: 2.1436, Perplexity: 8.530263\n",
      "Epoch [1/3], Step [8000/12942], Loss: 2.0210, Perplexity: 7.54581\n",
      "Epoch [1/3], Step [8100/12942], Loss: 2.0344, Perplexity: 7.64767\n",
      "Epoch [1/3], Step [8200/12942], Loss: 2.1073, Perplexity: 8.22617\n",
      "Epoch [1/3], Step [8300/12942], Loss: 2.1468, Perplexity: 8.55753\n",
      "Epoch [1/3], Step [8400/12942], Loss: 1.9525, Perplexity: 7.04629\n",
      "Epoch [1/3], Step [8500/12942], Loss: 2.5099, Perplexity: 12.3037\n",
      "Epoch [1/3], Step [8600/12942], Loss: 2.2396, Perplexity: 9.38968\n",
      "Epoch [1/3], Step [8700/12942], Loss: 2.2242, Perplexity: 9.24652\n",
      "Epoch [1/3], Step [8800/12942], Loss: 2.3528, Perplexity: 10.5145\n",
      "Epoch [1/3], Step [8900/12942], Loss: 2.2351, Perplexity: 9.34768\n",
      "Epoch [1/3], Step [9000/12942], Loss: 2.4868, Perplexity: 12.0229\n",
      "Epoch [1/3], Step [9100/12942], Loss: 2.1532, Perplexity: 8.61259\n",
      "Epoch [1/3], Step [9200/12942], Loss: 2.2533, Perplexity: 9.51957\n",
      "Epoch [1/3], Step [9300/12942], Loss: 2.0805, Perplexity: 8.00883\n",
      "Epoch [1/3], Step [9400/12942], Loss: 2.0209, Perplexity: 7.54553\n",
      "Epoch [1/3], Step [9500/12942], Loss: 2.2856, Perplexity: 9.83156\n",
      "Epoch [1/3], Step [9600/12942], Loss: 2.5371, Perplexity: 12.6424\n",
      "Epoch [1/3], Step [9700/12942], Loss: 2.3209, Perplexity: 10.1848\n",
      "Epoch [1/3], Step [9800/12942], Loss: 2.3866, Perplexity: 10.8764\n",
      "Epoch [1/3], Step [9900/12942], Loss: 2.2106, Perplexity: 9.12121\n",
      "Epoch [1/3], Step [10000/12942], Loss: 2.0974, Perplexity: 8.1447\n",
      "Epoch [1/3], Step [10100/12942], Loss: 2.2742, Perplexity: 9.72027\n",
      "Epoch [1/3], Step [10200/12942], Loss: 2.4108, Perplexity: 11.1433\n",
      "Epoch [1/3], Step [10300/12942], Loss: 2.4164, Perplexity: 11.2059\n",
      "Epoch [1/3], Step [10400/12942], Loss: 2.0837, Perplexity: 8.03444\n",
      "Epoch [1/3], Step [10500/12942], Loss: 2.0542, Perplexity: 7.80031\n",
      "Epoch [1/3], Step [10600/12942], Loss: 2.2008, Perplexity: 9.03229\n",
      "Epoch [1/3], Step [10700/12942], Loss: 2.4483, Perplexity: 11.5688\n",
      "Epoch [1/3], Step [10800/12942], Loss: 2.7124, Perplexity: 15.0660\n",
      "Epoch [1/3], Step [10900/12942], Loss: 2.2915, Perplexity: 9.88953\n",
      "Epoch [1/3], Step [11000/12942], Loss: 2.2465, Perplexity: 9.45425\n",
      "Epoch [1/3], Step [11100/12942], Loss: 2.1647, Perplexity: 8.71210\n",
      "Epoch [1/3], Step [11200/12942], Loss: 2.0762, Perplexity: 7.97435\n",
      "Epoch [1/3], Step [11300/12942], Loss: 2.0546, Perplexity: 7.80378\n",
      "Epoch [1/3], Step [11400/12942], Loss: 2.0113, Perplexity: 7.47294\n",
      "Epoch [1/3], Step [11500/12942], Loss: 2.6746, Perplexity: 14.5072\n",
      "Epoch [1/3], Step [11600/12942], Loss: 2.2186, Perplexity: 9.19422\n",
      "Epoch [1/3], Step [11700/12942], Loss: 1.8758, Perplexity: 6.52592\n",
      "Epoch [1/3], Step [11800/12942], Loss: 2.4171, Perplexity: 11.2138\n",
      "Epoch [1/3], Step [11900/12942], Loss: 2.1627, Perplexity: 8.69486\n",
      "Epoch [1/3], Step [12000/12942], Loss: 2.2243, Perplexity: 9.24746\n",
      "Epoch [1/3], Step [12100/12942], Loss: 2.1803, Perplexity: 8.84869\n",
      "Epoch [1/3], Step [12200/12942], Loss: 2.1950, Perplexity: 8.97962\n",
      "Epoch [1/3], Step [12300/12942], Loss: 2.7862, Perplexity: 16.2193\n",
      "Epoch [1/3], Step [12400/12942], Loss: 1.9977, Perplexity: 7.37228\n",
      "Epoch [1/3], Step [12500/12942], Loss: 2.2225, Perplexity: 9.23074\n",
      "Epoch [1/3], Step [12600/12942], Loss: 2.2936, Perplexity: 9.91047\n",
      "Epoch [1/3], Step [12700/12942], Loss: 2.2196, Perplexity: 9.20400\n",
      "Epoch [1/3], Step [12800/12942], Loss: 2.1234, Perplexity: 8.35960\n",
      "Epoch [1/3], Step [12900/12942], Loss: 2.3007, Perplexity: 9.98107\n",
      "Epoch [2/3], Step [100/12942], Loss: 2.2957, Perplexity: 9.9317863\n",
      "Epoch [2/3], Step [200/12942], Loss: 2.2517, Perplexity: 9.50365\n",
      "Epoch [2/3], Step [300/12942], Loss: 1.9297, Perplexity: 6.88727\n",
      "Epoch [2/3], Step [400/12942], Loss: 2.3425, Perplexity: 10.4072\n",
      "Epoch [2/3], Step [500/12942], Loss: 2.4102, Perplexity: 11.1362\n",
      "Epoch [2/3], Step [600/12942], Loss: 2.1309, Perplexity: 8.42239\n",
      "Epoch [2/3], Step [700/12942], Loss: 2.2574, Perplexity: 9.55797\n",
      "Epoch [2/3], Step [800/12942], Loss: 2.2266, Perplexity: 9.26814\n",
      "Epoch [2/3], Step [900/12942], Loss: 2.2317, Perplexity: 9.31556\n",
      "Epoch [2/3], Step [1000/12942], Loss: 2.1998, Perplexity: 9.0236\n",
      "Epoch [2/3], Step [1100/12942], Loss: 2.4595, Perplexity: 11.6995\n",
      "Epoch [2/3], Step [1200/12942], Loss: 1.9412, Perplexity: 6.96746\n",
      "Epoch [2/3], Step [1300/12942], Loss: 1.9832, Perplexity: 7.26590\n",
      "Epoch [2/3], Step [1400/12942], Loss: 1.8997, Perplexity: 6.68400\n",
      "Epoch [2/3], Step [1500/12942], Loss: 2.3716, Perplexity: 10.7147\n",
      "Epoch [2/3], Step [1600/12942], Loss: 2.0116, Perplexity: 7.47525\n",
      "Epoch [2/3], Step [1700/12942], Loss: 2.2550, Perplexity: 9.53552\n",
      "Epoch [2/3], Step [1800/12942], Loss: 2.0864, Perplexity: 8.05594\n",
      "Epoch [2/3], Step [1900/12942], Loss: 2.1518, Perplexity: 8.60026\n",
      "Epoch [2/3], Step [2000/12942], Loss: 1.9485, Perplexity: 7.01837\n",
      "Epoch [2/3], Step [2100/12942], Loss: 2.1018, Perplexity: 8.18106\n",
      "Epoch [2/3], Step [2200/12942], Loss: 1.8349, Perplexity: 6.26433\n",
      "Epoch [2/3], Step [2300/12942], Loss: 1.9487, Perplexity: 7.01948\n",
      "Epoch [2/3], Step [2400/12942], Loss: 2.1565, Perplexity: 8.64092\n",
      "Epoch [2/3], Step [2500/12942], Loss: 2.1696, Perplexity: 8.75453\n",
      "Epoch [2/3], Step [2600/12942], Loss: 1.8989, Perplexity: 6.67821\n",
      "Epoch [2/3], Step [2700/12942], Loss: 2.1587, Perplexity: 8.66037\n",
      "Epoch [2/3], Step [2800/12942], Loss: 2.4569, Perplexity: 11.6680\n",
      "Epoch [2/3], Step [2900/12942], Loss: 2.1297, Perplexity: 8.41273\n",
      "Epoch [2/3], Step [3000/12942], Loss: 2.2658, Perplexity: 9.63925\n",
      "Epoch [2/3], Step [3100/12942], Loss: 1.8756, Perplexity: 6.52486\n",
      "Epoch [2/3], Step [3200/12942], Loss: 2.1121, Perplexity: 8.26533\n",
      "Epoch [2/3], Step [3300/12942], Loss: 2.0776, Perplexity: 7.98502\n",
      "Epoch [2/3], Step [3400/12942], Loss: 2.1079, Perplexity: 8.23094\n",
      "Epoch [2/3], Step [3500/12942], Loss: 2.2351, Perplexity: 9.34758\n",
      "Epoch [2/3], Step [3600/12942], Loss: 2.0585, Perplexity: 7.83411\n",
      "Epoch [2/3], Step [3700/12942], Loss: 2.4504, Perplexity: 11.5929\n",
      "Epoch [2/3], Step [3800/12942], Loss: 1.9500, Perplexity: 7.02859\n",
      "Epoch [2/3], Step [3900/12942], Loss: 2.0155, Perplexity: 7.50437\n",
      "Epoch [2/3], Step [4000/12942], Loss: 2.1996, Perplexity: 9.02113\n",
      "Epoch [2/3], Step [4100/12942], Loss: 2.0236, Perplexity: 7.56555\n",
      "Epoch [2/3], Step [4200/12942], Loss: 1.9525, Perplexity: 7.04616\n",
      "Epoch [2/3], Step [4300/12942], Loss: 2.0898, Perplexity: 8.08355\n",
      "Epoch [2/3], Step [4400/12942], Loss: 2.4347, Perplexity: 11.41181\n",
      "Epoch [2/3], Step [4500/12942], Loss: 2.2433, Perplexity: 9.42432\n",
      "Epoch [2/3], Step [4600/12942], Loss: 1.7351, Perplexity: 5.66935\n",
      "Epoch [2/3], Step [4700/12942], Loss: 2.0054, Perplexity: 7.42919\n",
      "Epoch [2/3], Step [4800/12942], Loss: 2.0906, Perplexity: 8.08963\n",
      "Epoch [2/3], Step [4900/12942], Loss: 2.2592, Perplexity: 9.57583\n",
      "Epoch [2/3], Step [5000/12942], Loss: 2.0602, Perplexity: 7.84787\n",
      "Epoch [2/3], Step [5100/12942], Loss: 2.2292, Perplexity: 9.29244\n",
      "Epoch [2/3], Step [5200/12942], Loss: 2.2515, Perplexity: 9.50163\n",
      "Epoch [2/3], Step [5300/12942], Loss: 2.1274, Perplexity: 8.39331\n",
      "Epoch [2/3], Step [5400/12942], Loss: 2.1509, Perplexity: 8.59287\n",
      "Epoch [2/3], Step [5500/12942], Loss: 1.8172, Perplexity: 6.15499\n",
      "Epoch [2/3], Step [5600/12942], Loss: 2.1523, Perplexity: 8.60449\n",
      "Epoch [2/3], Step [5700/12942], Loss: 2.0622, Perplexity: 7.86354\n",
      "Epoch [2/3], Step [5800/12942], Loss: 1.9795, Perplexity: 7.23885\n",
      "Epoch [2/3], Step [5900/12942], Loss: 2.2885, Perplexity: 9.86044\n",
      "Epoch [2/3], Step [6000/12942], Loss: 1.9199, Perplexity: 6.82053\n",
      "Epoch [2/3], Step [6100/12942], Loss: 2.1476, Perplexity: 8.56444\n",
      "Epoch [2/3], Step [6200/12942], Loss: 2.5676, Perplexity: 13.0344\n",
      "Epoch [2/3], Step [6300/12942], Loss: 2.0551, Perplexity: 7.80767\n",
      "Epoch [2/3], Step [6400/12942], Loss: 2.0016, Perplexity: 7.40119\n",
      "Epoch [2/3], Step [6500/12942], Loss: 2.4532, Perplexity: 11.6257\n",
      "Epoch [2/3], Step [6600/12942], Loss: 1.8537, Perplexity: 6.38356\n",
      "Epoch [2/3], Step [6700/12942], Loss: 1.9840, Perplexity: 7.27177\n",
      "Epoch [2/3], Step [6800/12942], Loss: 2.3067, Perplexity: 10.0408\n",
      "Epoch [2/3], Step [6900/12942], Loss: 2.3651, Perplexity: 10.6456\n",
      "Epoch [2/3], Step [7000/12942], Loss: 2.1009, Perplexity: 8.17340\n",
      "Epoch [2/3], Step [7100/12942], Loss: 2.1002, Perplexity: 8.16776\n",
      "Epoch [2/3], Step [7200/12942], Loss: 2.8359, Perplexity: 17.0453\n",
      "Epoch [2/3], Step [7300/12942], Loss: 2.1411, Perplexity: 8.50847\n",
      "Epoch [2/3], Step [7400/12942], Loss: 1.9490, Perplexity: 7.02149\n",
      "Epoch [2/3], Step [7500/12942], Loss: 2.0296, Perplexity: 7.61098\n",
      "Epoch [2/3], Step [7600/12942], Loss: 2.1536, Perplexity: 8.61593\n",
      "Epoch [2/3], Step [7700/12942], Loss: 2.0515, Perplexity: 7.77943\n",
      "Epoch [2/3], Step [7800/12942], Loss: 1.9844, Perplexity: 7.27481\n",
      "Epoch [2/3], Step [7900/12942], Loss: 1.9443, Perplexity: 6.98907\n",
      "Epoch [2/3], Step [8000/12942], Loss: 1.7535, Perplexity: 5.77465\n",
      "Epoch [2/3], Step [8100/12942], Loss: 2.0136, Perplexity: 7.49049\n",
      "Epoch [2/3], Step [8200/12942], Loss: 1.8136, Perplexity: 6.13249\n",
      "Epoch [2/3], Step [8300/12942], Loss: 2.2157, Perplexity: 9.16786\n",
      "Epoch [2/3], Step [8400/12942], Loss: 3.6240, Perplexity: 37.4870\n",
      "Epoch [2/3], Step [8500/12942], Loss: 1.9046, Perplexity: 6.71694\n",
      "Epoch [2/3], Step [8600/12942], Loss: 1.8465, Perplexity: 6.33781\n",
      "Epoch [2/3], Step [8700/12942], Loss: 1.9533, Perplexity: 7.05206\n",
      "Epoch [2/3], Step [8800/12942], Loss: 2.1477, Perplexity: 8.56528\n",
      "Epoch [2/3], Step [8900/12942], Loss: 2.0339, Perplexity: 7.64371\n",
      "Epoch [2/3], Step [9000/12942], Loss: 2.1228, Perplexity: 8.35445\n",
      "Epoch [2/3], Step [9100/12942], Loss: 2.0551, Perplexity: 7.80772\n",
      "Epoch [2/3], Step [9200/12942], Loss: 1.8021, Perplexity: 6.06230\n",
      "Epoch [2/3], Step [9300/12942], Loss: 2.0841, Perplexity: 8.03723\n",
      "Epoch [2/3], Step [9400/12942], Loss: 1.9237, Perplexity: 6.84635\n",
      "Epoch [2/3], Step [9500/12942], Loss: 2.1817, Perplexity: 8.86108\n",
      "Epoch [2/3], Step [9600/12942], Loss: 1.9190, Perplexity: 6.81409\n",
      "Epoch [2/3], Step [9700/12942], Loss: 2.2313, Perplexity: 9.31169\n",
      "Epoch [2/3], Step [9800/12942], Loss: 1.8645, Perplexity: 6.45267\n",
      "Epoch [2/3], Step [9900/12942], Loss: 1.9372, Perplexity: 6.93931\n",
      "Epoch [2/3], Step [10000/12942], Loss: 2.3360, Perplexity: 10.3401\n",
      "Epoch [2/3], Step [10100/12942], Loss: 1.8654, Perplexity: 6.45837\n",
      "Epoch [2/3], Step [10200/12942], Loss: 1.9953, Perplexity: 7.35471\n",
      "Epoch [2/3], Step [10300/12942], Loss: 2.3239, Perplexity: 10.2152\n",
      "Epoch [2/3], Step [10400/12942], Loss: 2.0443, Perplexity: 7.72348\n",
      "Epoch [2/3], Step [10500/12942], Loss: 1.7952, Perplexity: 6.02093\n",
      "Epoch [2/3], Step [10600/12942], Loss: 2.1041, Perplexity: 8.19972\n",
      "Epoch [2/3], Step [10700/12942], Loss: 1.9959, Perplexity: 7.35911\n",
      "Epoch [2/3], Step [10800/12942], Loss: 2.1527, Perplexity: 8.60830\n",
      "Epoch [2/3], Step [10900/12942], Loss: 2.1264, Perplexity: 8.38502\n",
      "Epoch [2/3], Step [11000/12942], Loss: 1.8878, Perplexity: 6.60467\n",
      "Epoch [2/3], Step [11100/12942], Loss: 1.9773, Perplexity: 7.22339\n",
      "Epoch [2/3], Step [11200/12942], Loss: 1.9724, Perplexity: 7.18766\n",
      "Epoch [2/3], Step [11300/12942], Loss: 1.8234, Perplexity: 6.19260\n",
      "Epoch [2/3], Step [11400/12942], Loss: 1.8035, Perplexity: 6.07094\n",
      "Epoch [2/3], Step [11500/12942], Loss: 1.6979, Perplexity: 5.46258\n",
      "Epoch [2/3], Step [11600/12942], Loss: 2.1105, Perplexity: 8.25255\n",
      "Epoch [2/3], Step [11700/12942], Loss: 1.9322, Perplexity: 6.90463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Step [11800/12942], Loss: 1.6790, Perplexity: 5.36040\n",
      "Epoch [2/3], Step [11900/12942], Loss: 2.6318, Perplexity: 13.8984\n",
      "Epoch [2/3], Step [12000/12942], Loss: 1.7373, Perplexity: 5.68199\n",
      "Epoch [2/3], Step [12100/12942], Loss: 1.8293, Perplexity: 6.22944\n",
      "Epoch [2/3], Step [12200/12942], Loss: 1.9815, Perplexity: 7.25397\n",
      "Epoch [2/3], Step [12300/12942], Loss: 2.3926, Perplexity: 10.9419\n",
      "Epoch [2/3], Step [12400/12942], Loss: 1.5793, Perplexity: 4.85162\n",
      "Epoch [2/3], Step [12500/12942], Loss: 1.9680, Perplexity: 7.15629\n",
      "Epoch [2/3], Step [12600/12942], Loss: 2.3612, Perplexity: 10.6041\n",
      "Epoch [2/3], Step [12700/12942], Loss: 2.0609, Perplexity: 7.85342\n",
      "Epoch [2/3], Step [12800/12942], Loss: 2.0291, Perplexity: 7.60700\n",
      "Epoch [2/3], Step [12900/12942], Loss: 2.0696, Perplexity: 7.92162\n",
      "Epoch [3/3], Step [100/12942], Loss: 2.2110, Perplexity: 9.1244004\n",
      "Epoch [3/3], Step [200/12942], Loss: 1.9603, Perplexity: 7.10147\n",
      "Epoch [3/3], Step [300/12942], Loss: 2.0594, Perplexity: 7.84131\n",
      "Epoch [3/3], Step [400/12942], Loss: 2.1978, Perplexity: 9.00552\n",
      "Epoch [3/3], Step [500/12942], Loss: 1.8407, Perplexity: 6.30124\n",
      "Epoch [3/3], Step [600/12942], Loss: 2.0153, Perplexity: 7.50289\n",
      "Epoch [3/3], Step [700/12942], Loss: 1.8356, Perplexity: 6.26884\n",
      "Epoch [3/3], Step [800/12942], Loss: 1.9449, Perplexity: 6.99289\n",
      "Epoch [3/3], Step [900/12942], Loss: 1.9401, Perplexity: 6.95929\n",
      "Epoch [3/3], Step [1000/12942], Loss: 1.9241, Perplexity: 6.8492\n",
      "Epoch [3/3], Step [1100/12942], Loss: 2.3907, Perplexity: 10.9207\n",
      "Epoch [3/3], Step [1200/12942], Loss: 1.8927, Perplexity: 6.63762\n",
      "Epoch [3/3], Step [1300/12942], Loss: 2.0334, Perplexity: 7.64026\n",
      "Epoch [3/3], Step [1400/12942], Loss: 1.9906, Perplexity: 7.32002\n",
      "Epoch [3/3], Step [1500/12942], Loss: 2.2161, Perplexity: 9.17188\n",
      "Epoch [3/3], Step [1600/12942], Loss: 2.1163, Perplexity: 8.30056\n",
      "Epoch [3/3], Step [1700/12942], Loss: 2.0105, Perplexity: 7.46700\n",
      "Epoch [3/3], Step [1800/12942], Loss: 1.9721, Perplexity: 7.18562\n",
      "Epoch [3/3], Step [1900/12942], Loss: 1.7356, Perplexity: 5.67226\n",
      "Epoch [3/3], Step [2000/12942], Loss: 1.7310, Perplexity: 5.64656\n",
      "Epoch [3/3], Step [2100/12942], Loss: 1.9930, Perplexity: 7.33771\n",
      "Epoch [3/3], Step [2200/12942], Loss: 2.2797, Perplexity: 9.77427\n",
      "Epoch [3/3], Step [2300/12942], Loss: 2.0854, Perplexity: 8.04811\n",
      "Epoch [3/3], Step [2400/12942], Loss: 1.9687, Perplexity: 7.16132\n",
      "Epoch [3/3], Step [2500/12942], Loss: 2.1286, Perplexity: 8.40300\n",
      "Epoch [3/3], Step [2600/12942], Loss: 2.0161, Perplexity: 7.50896\n",
      "Epoch [3/3], Step [2700/12942], Loss: 2.1518, Perplexity: 8.60060\n",
      "Epoch [3/3], Step [2800/12942], Loss: 2.0731, Perplexity: 7.94936\n",
      "Epoch [3/3], Step [2900/12942], Loss: 2.1421, Perplexity: 8.51760\n",
      "Epoch [3/3], Step [3000/12942], Loss: 2.0734, Perplexity: 7.951832\n",
      "Epoch [3/3], Step [3100/12942], Loss: 1.8195, Perplexity: 6.16883\n",
      "Epoch [3/3], Step [3200/12942], Loss: 2.1503, Perplexity: 8.58773\n",
      "Epoch [3/3], Step [3300/12942], Loss: 2.0152, Perplexity: 7.50258\n",
      "Epoch [3/3], Step [3400/12942], Loss: 1.9580, Perplexity: 7.08555\n",
      "Epoch [3/3], Step [3500/12942], Loss: 1.9168, Perplexity: 6.79934\n",
      "Epoch [3/3], Step [3600/12942], Loss: 2.3643, Perplexity: 10.6370\n",
      "Epoch [3/3], Step [3700/12942], Loss: 2.0851, Perplexity: 8.04578\n",
      "Epoch [3/3], Step [3800/12942], Loss: 2.6309, Perplexity: 13.8865\n",
      "Epoch [3/3], Step [3900/12942], Loss: 1.9529, Perplexity: 7.04890\n",
      "Epoch [3/3], Step [4000/12942], Loss: 1.9606, Perplexity: 7.10389\n",
      "Epoch [3/3], Step [4100/12942], Loss: 2.0122, Perplexity: 7.47981\n",
      "Epoch [3/3], Step [4200/12942], Loss: 1.9159, Perplexity: 6.79303\n",
      "Epoch [3/3], Step [4300/12942], Loss: 2.1177, Perplexity: 8.31165\n",
      "Epoch [3/3], Step [4400/12942], Loss: 2.0021, Perplexity: 7.40476\n",
      "Epoch [3/3], Step [4500/12942], Loss: 1.8759, Perplexity: 6.52662\n",
      "Epoch [3/3], Step [4600/12942], Loss: 2.2187, Perplexity: 9.19568\n",
      "Epoch [3/3], Step [4700/12942], Loss: 1.9131, Perplexity: 6.77390\n",
      "Epoch [3/3], Step [4800/12942], Loss: 1.8595, Perplexity: 6.42043\n",
      "Epoch [3/3], Step [4900/12942], Loss: 2.0483, Perplexity: 7.75513\n",
      "Epoch [3/3], Step [5000/12942], Loss: 2.0348, Perplexity: 7.65069\n",
      "Epoch [3/3], Step [5100/12942], Loss: 1.9628, Perplexity: 7.11944\n",
      "Epoch [3/3], Step [5200/12942], Loss: 2.6219, Perplexity: 13.7619\n",
      "Epoch [3/3], Step [5300/12942], Loss: 2.1536, Perplexity: 8.61552\n",
      "Epoch [3/3], Step [5400/12942], Loss: 2.1827, Perplexity: 8.87064\n",
      "Epoch [3/3], Step [5500/12942], Loss: 1.8865, Perplexity: 6.59625\n",
      "Epoch [3/3], Step [5600/12942], Loss: 1.9649, Perplexity: 7.13433\n",
      "Epoch [3/3], Step [5700/12942], Loss: 1.7729, Perplexity: 5.88770\n",
      "Epoch [3/3], Step [5800/12942], Loss: 1.9464, Perplexity: 7.00315\n",
      "Epoch [3/3], Step [5900/12942], Loss: 2.0547, Perplexity: 7.80478\n",
      "Epoch [3/3], Step [6000/12942], Loss: 2.0209, Perplexity: 7.54489\n",
      "Epoch [3/3], Step [6100/12942], Loss: 1.8097, Perplexity: 6.10886\n",
      "Epoch [3/3], Step [6200/12942], Loss: 1.9913, Perplexity: 7.32489\n",
      "Epoch [3/3], Step [6300/12942], Loss: 1.9441, Perplexity: 6.98705\n",
      "Epoch [3/3], Step [6400/12942], Loss: 1.8789, Perplexity: 6.54629\n",
      "Epoch [3/3], Step [6500/12942], Loss: 2.0447, Perplexity: 7.72655\n",
      "Epoch [3/3], Step [6600/12942], Loss: 1.8928, Perplexity: 6.63786\n",
      "Epoch [3/3], Step [6700/12942], Loss: 2.1807, Perplexity: 8.85258\n",
      "Epoch [3/3], Step [6800/12942], Loss: 2.1034, Perplexity: 8.19372\n",
      "Epoch [3/3], Step [6900/12942], Loss: 2.0421, Perplexity: 7.706757\n",
      "Epoch [3/3], Step [7000/12942], Loss: 2.0843, Perplexity: 8.03872\n",
      "Epoch [3/3], Step [7100/12942], Loss: 2.0662, Perplexity: 7.89508\n",
      "Epoch [3/3], Step [7200/12942], Loss: 2.1053, Perplexity: 8.20949\n",
      "Epoch [3/3], Step [7300/12942], Loss: 2.6352, Perplexity: 13.9466\n",
      "Epoch [3/3], Step [7400/12942], Loss: 1.9643, Perplexity: 7.12981\n",
      "Epoch [3/3], Step [7500/12942], Loss: 2.1005, Perplexity: 8.17041\n",
      "Epoch [3/3], Step [7600/12942], Loss: 2.0489, Perplexity: 7.75920\n",
      "Epoch [3/3], Step [7700/12942], Loss: 1.9256, Perplexity: 6.85925\n",
      "Epoch [3/3], Step [7800/12942], Loss: 2.4621, Perplexity: 11.7292\n",
      "Epoch [3/3], Step [7900/12942], Loss: 2.1628, Perplexity: 8.69544\n",
      "Epoch [3/3], Step [8000/12942], Loss: 1.9199, Perplexity: 6.81990\n",
      "Epoch [3/3], Step [8100/12942], Loss: 2.0586, Perplexity: 7.83504\n",
      "Epoch [3/3], Step [8200/12942], Loss: 2.1357, Perplexity: 8.46301\n",
      "Epoch [3/3], Step [8300/12942], Loss: 1.6610, Perplexity: 5.26444\n",
      "Epoch [3/3], Step [8400/12942], Loss: 2.0266, Perplexity: 7.58800\n",
      "Epoch [3/3], Step [8500/12942], Loss: 2.0358, Perplexity: 7.65877\n",
      "Epoch [3/3], Step [8600/12942], Loss: 2.2942, Perplexity: 9.91606\n",
      "Epoch [3/3], Step [8700/12942], Loss: 2.0745, Perplexity: 7.96053\n",
      "Epoch [3/3], Step [8800/12942], Loss: 1.9429, Perplexity: 6.97872\n",
      "Epoch [3/3], Step [8900/12942], Loss: 1.6793, Perplexity: 5.36191\n",
      "Epoch [3/3], Step [9000/12942], Loss: 1.6674, Perplexity: 5.29840\n",
      "Epoch [3/3], Step [9100/12942], Loss: 2.0508, Perplexity: 7.77396\n",
      "Epoch [3/3], Step [9200/12942], Loss: 1.8859, Perplexity: 6.59214\n",
      "Epoch [3/3], Step [9300/12942], Loss: 2.2023, Perplexity: 9.04595\n",
      "Epoch [3/3], Step [9400/12942], Loss: 2.2476, Perplexity: 9.46485\n",
      "Epoch [3/3], Step [9500/12942], Loss: 1.8857, Perplexity: 6.59135\n",
      "Epoch [3/3], Step [9600/12942], Loss: 2.0436, Perplexity: 7.71803\n",
      "Epoch [3/3], Step [9700/12942], Loss: 1.8486, Perplexity: 6.35120\n",
      "Epoch [3/3], Step [9800/12942], Loss: 2.1763, Perplexity: 8.81327\n",
      "Epoch [3/3], Step [9900/12942], Loss: 2.1145, Perplexity: 8.28550\n",
      "Epoch [3/3], Step [10000/12942], Loss: 1.9078, Perplexity: 6.7379\n",
      "Epoch [3/3], Step [10100/12942], Loss: 1.9831, Perplexity: 7.26520\n",
      "Epoch [3/3], Step [10200/12942], Loss: 2.2659, Perplexity: 9.63946\n",
      "Epoch [3/3], Step [10300/12942], Loss: 2.0602, Perplexity: 7.84730\n",
      "Epoch [3/3], Step [10400/12942], Loss: 1.9965, Perplexity: 7.36343\n",
      "Epoch [3/3], Step [10500/12942], Loss: 1.6900, Perplexity: 5.41955\n",
      "Epoch [3/3], Step [10600/12942], Loss: 1.7523, Perplexity: 5.76806\n",
      "Epoch [3/3], Step [10700/12942], Loss: 1.9230, Perplexity: 6.84122\n",
      "Epoch [3/3], Step [10800/12942], Loss: 1.8199, Perplexity: 6.17128\n",
      "Epoch [3/3], Step [10900/12942], Loss: 2.0410, Perplexity: 7.69830\n",
      "Epoch [3/3], Step [11000/12942], Loss: 2.0067, Perplexity: 7.43895\n",
      "Epoch [3/3], Step [11100/12942], Loss: 1.9561, Perplexity: 7.07182\n",
      "Epoch [3/3], Step [11200/12942], Loss: 1.9864, Perplexity: 7.28907\n",
      "Epoch [3/3], Step [11300/12942], Loss: 1.7577, Perplexity: 5.79886\n",
      "Epoch [3/3], Step [11400/12942], Loss: 2.0120, Perplexity: 7.47800\n",
      "Epoch [3/3], Step [11500/12942], Loss: 1.8254, Perplexity: 6.20531\n",
      "Epoch [3/3], Step [11600/12942], Loss: 1.8116, Perplexity: 6.12016\n",
      "Epoch [3/3], Step [11700/12942], Loss: 1.8831, Perplexity: 6.57360\n",
      "Epoch [3/3], Step [11800/12942], Loss: 1.8358, Perplexity: 6.27016\n",
      "Epoch [3/3], Step [11900/12942], Loss: 2.0861, Perplexity: 8.05341\n",
      "Epoch [3/3], Step [12000/12942], Loss: 1.8333, Perplexity: 6.25433\n",
      "Epoch [3/3], Step [12100/12942], Loss: 1.9046, Perplexity: 6.71642\n",
      "Epoch [3/3], Step [12200/12942], Loss: 2.1289, Perplexity: 8.40578\n",
      "Epoch [3/3], Step [12300/12942], Loss: 1.9432, Perplexity: 6.98136\n",
      "Epoch [3/3], Step [12400/12942], Loss: 1.8245, Perplexity: 6.19999\n",
      "Epoch [3/3], Step [12500/12942], Loss: 1.9886, Perplexity: 7.30523\n",
      "Epoch [3/3], Step [12600/12942], Loss: 1.8945, Perplexity: 6.64920\n",
      "Epoch [3/3], Step [12700/12942], Loss: 2.0532, Perplexity: 7.79271\n",
      "Epoch [3/3], Step [12800/12942], Loss: 1.9516, Perplexity: 7.04019\n",
      "Epoch [3/3], Step [12900/12942], Loss: 2.2033, Perplexity: 9.05492\n",
      "Epoch [3/3], Step [12942/12942], Loss: 1.9881, Perplexity: 7.30160"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
